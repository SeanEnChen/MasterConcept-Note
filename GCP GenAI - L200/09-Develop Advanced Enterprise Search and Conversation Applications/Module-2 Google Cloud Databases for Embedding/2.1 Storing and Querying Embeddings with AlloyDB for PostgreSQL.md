# 9.2.1 Storing and Querying Embeddings with AlloyDB for PostgreSQL

這個 Lab 一開始一樣先安裝套件，然後這個 Lab 會將資料儲存在AlloyDB 中，他是一個結合 PostgreSQL 的資料庫，Lab 提供的 AlloyDB 有一個 Private IP 用於 Python 與 AlloyDB 的連接，透過以下程式碼連接之後，再將載入的 CSV data 轉換成 Data Frame 之後存入 AlloyDB。

```Python
import psycopg2

# Replace with your AlloyDB cluster credentials
cluster_ip_address = "10.66.0.2"
database_user = "postgres"
database_password = "postgres"

# Set environment variables for psql connection
os.environ["PGHOST"] = cluster_ip_address
os.environ["PGUSER"] = database_user
os.environ["PGPASSWORD"] = database_password

# Establish a connection to the database
try:
    conn = psycopg2.connect(
        host=cluster_ip_address,
        user=database_user,
        password=database_password
    )
    print("Connected to the database successfully!")
except Exception as e:
    print("Connection error:", e)
exit(1)

# Read the dataset from the URL
DATASET_URL = "https://github.com/GoogleCloudPlatform/python-docs-samples/raw/main/cloud-sql/postgres/pgvector/data/retail_toy_dataset.csv"
df = pd.read_csv(DATASET_URL)

# Select desired columns and drop missing values
df = df.loc[:, ["product_id", "product_name", "description", "list_price"]]
df = df.dropna()

# Save the DataFrame to the AlloyDB cluster
df.to_sql('products', con=f'postgresql://{cluster_ip_address}', if_exists='replace', index=False)

# Retrieve data from the 'products' table
cur = conn.cursor()
cur.execute("SELECT * FROM products")
results = cur.fetchall()

# Close the connection
conn.close()
print(results[5])
```

好了之後接著要對太長的 description 進行切割，而這邊只使用第 40～50 筆資料，然後將 chunk 完的 Data Frame 針對 content 欄位進行 Embedding，然後會多一個新的 embedding 欄位。然後透過 gcloud 指令賦予 AlloyDB 可以訪問 Vertex AI 的權限，目的是為了實現 similarity search 的功能。授予權限之後，可以登入 AlloyDB Studio，可以在這上面透過以下指令，直接使用 Vertex AI 的 Embedding Model。

```SQL
GRANT EXECUTE ON FUNCTION embedding TO postgres;

CREATE EXTENSION IF NOT EXISTS google_ml_integration CASCADE;

SELECT embedding('text-embedding-004', 'AlloyDB is a managed, cloud-hosted SQL database service.');
```

確認可以使用 Embedding Model 之後，在 AlloyDB 中建立一個新的 table，包含 id、content、embedding 三個欄位，而 embedding 當然是基於 content 欄位，指令如下：

```SQL
CREATE TABLE product_embeddings(
        product_id VARCHAR(1024) NOT NULL PRIMARY KEY,
        content TEXT,
        embedding vector(768)
    );


insert into product_embeddings(product_id, content, embedding)
SELECT
product_id,
description as content,
embedding('text-embedding-004', description) as embedding
from products
where product_id not in (select product_id from product_embeddings)
limit 10;
```

接著可以在新的 table 上建立 index，而 index 的方式有兩種，分別是 **HNSW** 和 **IVFFLAT**，這種索引方式在 [[G/GCP GenAI - L200/08-Custom Search with Embeddings in Vertex AI/Module-3 Storing and Serving Embeddings/3.1 Managing Embeddings in PostgreSQL]] 有提到，而指令如下：

```SQL
-- Create an HNSW index on the `product_embeddings` table
CREATE INDEX ON product_embeddings
USING hnsw(embedding vector_cosine_ops)
WITH (m = 24, ef_construction = 100);

-- Create an IVFFLAT index on the `product_embeddings` table
CREATE INDEX ON product_embeddings
USING ivfflat(embedding vector_cosine_ops)
WITH (lists = 100);
```

好了之後接下來就是進行 Query，透過以下指令，即可返回 retrieve 的結果：

```SQL
with e as (
SELECT
    *
FROM
    product_embeddings
ORDER BY
    embedding <-> CAST(embedding('text-embedding-004','Playing card games') AS vector(768)) asc
LIMIT
    5
)
select
*
from products
where product_id in (select e.product_id from e);
```

回到程式碼這邊，接下來要用 pgvector 來搜尋 AlloyDB 裡面的資料，可以透過程式碼執行

```Python
import psycopg2
from psycopg2 import sql
from pgvector.psycopg2 import register_vector
import pandas as pd

def main(user_query, min_price, max_price):
    try:
        # AlloyDB cluster connection details (replace with your actual values)
        cluster_ip_address = "10.66.0.2"
        database_user = "postgres"
        database_password = "postgres"

        # Connect to AlloyDB cluster
        conn = psycopg2.connect(
            host=cluster_ip_address,
            user=database_user,
            password=database_password
        )

        # Register the vector type
        register_vector(conn)

        # Get the query embedding
        qe = embeddings_service.embed_query(user_query)

        # Check if qe is valid
        if not qe:
            print("Error: The query embedding is empty.")
            return

        # Perform the similarity search and filtering
        cur = conn.cursor()
        similarity_threshold = 0.5  # Increased threshold for broader matching
        num_matches = 50

        # Modify the SQL query for indexed similarity search
        cur.execute(
            """
            WITH vector_matches AS (
                SELECT *
                FROM product_embeddings
                ORDER BY embedding <-> CAST(embedding('text-embedding-004','Do you have a toy set that teaches numbers and letters to kids?') AS vector(768)) asc
                LIMIT %s
            )
            SELECT product_name, list_price, description
            FROM products
            WHERE product_id IN (SELECT product_id FROM vector_matches)
            AND list_price >= %s AND list_price <= %s
            """,
            (num_matches, min_price, max_price)
        )
        results = cur.fetchall()

        # Check if any results are retrieved
        if not results:
            print("No results found. Try adjusting the similarity threshold or checking the data.")
            return

        # Process the results
        matches = []
        for r in results:
            try:
                list_price = round(float(r[1]), 2)  # Attempt conversion and rounding
            except ValueError:
                list_price = r[1]  # Use original value if conversion fails
            matches.append({
                "product_name": r[0],
                "list_price": list_price,
                "description": r[2]
            })

        # Display the results
        matches_df = pd.DataFrame(matches)
        print(matches_df.head(5))

    except Exception as e:
        print(f"Error during database operations: {e}")
    finally:
        # Close the connection
        if conn:
            conn.close()

# Call the main function
main("Do you have a toy set that teaches numbers and letters to kids?", 25, 100)
```

上面使用 pgvector 找到相似的產品及其描述后，下一步是使用它們為LLM模型生成提示輸入。由於單個產品描述可能很長，因此它們可能超過 LLM 模型的 Token 限制。 `來自 LangChain` 框架的 `MapReduceChain` 用於生成和組合類似匹配產品的簡短摘要。然後，使用組合的摘要構建高品質的提示，以便為LLM模型輸入。

```Python
from IPython.display import display, Markdown
from langchain_core.documents.base import Document
from langchain.chains.summarize import load_summarize_chain
from langchain_google_vertexai import VertexAI
from langchain_core.prompts import PromptTemplate

# Mock matches data
matches = [
    {"product_name": "Alphabet Learning Toy", "price": 30, "features": "Teaches letters and numbers."},
    {"product_name": "Number Puzzle", "price": 20, "features": "Interactive puzzle for number learning."},
]

# LangChain setup
llm = VertexAI(model_name="gemini-pro")

map_prompt_template = """
            You will be given a detailed description of a toy product.
            This description is enclosed in triple backticks (```).
            Using this description only, extract the name of the toy,
            the price of the toy and its features.

            ```{text}```
            SUMMARY:
            """
map_prompt = PromptTemplate(template=map_prompt_template, input_variables=["text"])

combine_prompt_template = """
                You will be given a detailed description of different toy products
                enclosed in triple backticks (```) and a question enclosed in
                double backticks(``).
                Select one toy that is most relevant to answer the question.
                Using that selected toy description, answer the following
                question in as much detail as possible.
                You should only use the information in the description.
                Your answer should include the name of the toy, the price of the toy
                and its features. Your answer should be less than 200 words.
                Your answer should be in Markdown in a numbered list format.

                Description:
                ```{text}```

                Question:
                ``{user_query}``

                Answer:
                """
combine_prompt = PromptTemplate(
    template=combine_prompt_template, input_variables=["text", "user_query"]
)

# Convert matches to LangChain documents
docs = [
    Document(page_content=f"Name: {match['product_name']}, Price: {match['price']}, Features: {match['features']}")
    for match in matches
]

# Load and invoke the chain
chain = load_summarize_chain(
    llm, chain_type="map_reduce", map_prompt=map_prompt, combine_prompt=combine_prompt
)

# User query
user_query = "Do you have a toy set that teaches numbers and letters to kids?"

# Invoke the chain
output = chain.invoke({
    "input_documents": docs,
    "user_query": user_query,
})

# Extract and display the output
answer = output.get('output_text', ' ')
display(Markdown(answer))
```

上面是用 mock 的 document 作為提示資料，現在將串接 AlloyDB 和 LangChain 和 LLM，來根據 User Query 回傳結果。

```Python
import psycopg2
from pgvector.psycopg2 import register_vector

def main():
    try:
        # AlloyDB cluster connection details
        cluster_ip_address = "10.66.0.2"
        database_user = "postgres"
        database_password = "postgres"

        # Connect to AlloyDB cluster
        conn = psycopg2.connect(
            host=cluster_ip_address,
            user=database_user,
            password=database_password
        )

        # Register the vector type
        register_vector(conn)

        # Get the query embedding
        qe = embeddings_service.embed_query(creative_prompt)

        # Check if qe is a valid embedding
        if not qe:
            print("Error: The query embedding is empty.")
            return

        # Set similarity threshold
        similarity_threshold = 0.5
        matches = []

        # Perform the similarity search and filtering
        cur = conn.cursor()
        cur.execute(
            """
            WITH vector_matches AS (
                SELECT product_id, embedding <=> %s::vector AS distance
                FROM product_embeddings
                WHERE embedding <=> %s::vector < %s
                ORDER BY distance ASC
                LIMIT 3
            )
            SELECT description FROM products
            WHERE product_id IN (SELECT product_id FROM vector_matches)
            """,
            (qe, qe, similarity_threshold)
        )

        results = cur.fetchall()

        # Process the results
        for r in results:
            matches.append(r[0])

        if not matches:
            print("No matches found.")
        else:
            print("Matches found:", matches)
            return results

    except Exception as e:
        print(f"Error during database operations: {e}")
    finally:
        # Close the connection if it was established
        if conn:
            conn.close()

# Call the main function
matches = main()


from IPython.display import display, Markdown
from langchain_google_vertexai import VertexAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableSequence

# Define the template
template = """
            You are given descriptions about some similar kind of toys in the context.
            This context is enclosed in triple backticks (```).
            Combine these descriptions and adapt them to match the specifications in
            the initial prompt. All the information from the initial prompt must
            be included. You are allowed to be as creative as possible,
            and describe the new toy in as much detail. Your answer should be
            in markdown in lists and less than 200 words.

            Context:
            ```{context}```

            Initial Prompt:
            {creative_prompt}

            Answer:
        """

prompt = PromptTemplate(
    template=template, input_variables=["context", "creative_prompt"]
)

# Define the LLM
llm = VertexAI(model_name="gemini-pro", temperature=0.7)

# Example `matches` list
matches = [
    {"description": "This is a toy description 1."},
    {"description": "This is a toy description 2."},
    {},  # Missing `description`
    "Invalid item"  # Not a dictionary
]

# Construct the context by extracting valid descriptions
context = "\n".join(
    item["description"] for item in matches if isinstance(item, dict) and "description" in item
)

# Define the creative prompt
creative_prompt = "Describe a toy that is suitable for both indoor and outdoor play."

# Use RunnableSequence for chaining
llm_chain = RunnableSequence(prompt | llm)

# Invoke the chain
answer = llm_chain.invoke({
    "context": context,
    "creative_prompt": creative_prompt,
})

# Display the answer in Markdown format
display(Markdown(answer))
```

把 AlloyDB 回傳的 matches，用 LangChain 這邊設定好的 matches 的格式，就可以將這個 RAG 的 flow 給串接起來了！！