# 4.1 Introduction to Image Generation

**核心概念：**

- diffusion model 是一種新興且強大的圖像生成技術，近年來在圖像生成領域展現出巨大的潛力。
- 圖像生成方法（如 VAE、GAN、autoregressive model）不同，擴散模型採取了獨特的方法。
	- VAE：Variational autoencoder，他將圖像編碼至一個壓縮後的尺寸，然後再將其解碼回原始尺寸，同時學習數據自身的分布。
	- GAN：Generative adversarial model，他會讓兩個神經網路彼此競爭：一個 neural network 負責創造圖像，另一個 neural network 則負責判斷圖像的真偽。隨著訓練的進行，負責鑑別的 neural network 會更擅長辨別真假，而負責生成的 neural network 也會更擅長創造看起來更真實的假圖像。
	- autoregressive model：將圖像視為一個像素序列來產生圖像。他的方法，實際上很大程度是受到大型語言模型（LLMs）處理文本方式的啟發。

**運作原理：**

diffusion model 透過一個迭代性的 forward diffusion 過程來破壞圖像的結構和數據分布，然後學習一個reverse diffusion 過程來恢復這些結構和數據。其目標是，透過訓練模型去除 noise，這個模型就能夠接收 pure noise，並從中合成全新的圖像。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1743387800000roci5u.png)

我們從一個龐大的圖像數據集開始，就以左邊這個單張圖像為例。我們啟動 forward diffusion 過程，從初始圖像 x0 開始，逐步加入噪音，得到 x1（帶有一點噪音的圖像）。我們可以重複這個迭代過程，不斷地向圖像中添加更多噪音。我們將這個過程產生的分布稱為 Q，它只依賴於前一個步驟。理想情況下，經過足夠多次（例如 T 次）的迭代，我們最終會得到完全是噪音的狀態。最初的研究論文中，這個 T 值設定為 1000。

現在，我們想要反過來進行這個過程：在每一步中，如何從一個充滿噪音的圖像 XT 回到一個稍微減少噪音的圖像 XT-1？我們也需要學習這個反向擴散過程，也就是訓練一個機器學習模型，這個模型以帶有噪音的圖像和時間步 T 作為輸入，並預測在這個時間步應該去除的噪音。

**DDPM Training：**

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1743387960000ejxre4.png)

從原始圖像 X 開始，並在時間步 T 進行採樣，以創建一個帶有噪音的圖像。接著，我們訓練一個去噪模型來預測在這個時間步加入的噪音。這個模型的訓練目標是最小化其預測的噪音與實際加入到圖像中的噪音之間的差異。換句話說，這個模型學習如何從真實圖像中去除噪音。

**DDPM Generation：**

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1743388068000fljllr.png)

為了生成新的圖像，我們可以從純粹的噪音開始，並將其輸入到我們訓練好的去噪模型中。模型會預測出在這個階段應該去除的噪音，然後我們將這個預測的噪音從當前的噪音圖像中減去。如果我們一遍又一遍地重複這個過程，最終我們會得到一個生成的圖像。
另一種理解方式是，這個模型已經學習了它所見過的真實圖像的數據分布，並且能夠從這個學習到的分布中進行採樣，從而創造出全新的圖像。

**應用領域：**

- **Unconditional Generation：** 指模型在沒有任何額外輸入或指令的情況下，可以針對特定事物的圖像進行訓練，以生成該事物的新圖像，例如人臉。無條件生成的另一個例子是超解析度，也就是提高圖像品質。
- **Conditional Generation：**
	- **文字到圖像 (Text-to-Image):** 根據文字 Prompt 的描述生成對應的圖像，也可以對現有圖像進行編輯和修改。

**總結：**

擴散模型通過 forward diffusion 和學習反向去噪的過程，實現了強大的圖像生成能力。這項技術在各個領域都展現出巨大的潛力，並且正在快速發展，未來有望在更多領域得到應用。講者也提到這項技術將被整合到 Google Cloud 的 Vertex AI 平台中。