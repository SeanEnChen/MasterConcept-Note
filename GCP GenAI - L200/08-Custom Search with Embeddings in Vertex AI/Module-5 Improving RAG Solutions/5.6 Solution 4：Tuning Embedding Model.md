# 8.5.6 Solution 4：Tuning Embedding Model

**核心主題：介紹第四種提升 RAG 相關性的方法——直接調整或微調嵌入模型本身，特別是利用 Vertex AI 提供的監督式微調功能。**

**模型調整 (Tuning) 的類型：**

1. **完整微調 (Full Fine-tuning)**：
    - 產生一個全新的模型副本。
    - 非常昂貴，需要大量資料和運算資源。
    - **目前不建議用於嵌入模型，且在 Vertex AI 中不適用於嵌入模型**。（文中以 Med-PaLM 作為文字模型完整微調的例子）。
2. **參數高效微調 (Parameter-Efficient Fine-Tuning, PEFT)**：
    - 在基礎模型之上**增加**額外的、較小的權重層。
    - 需要的資料量少得多（數百到數千個範例即可）。
    - 可以使用 Vertex AI 自動化完成。
    - **這是本段討論用於嵌入模型的方法**。（文中以 Codey 模型作為 PEFT 的例子）。
    - **建議**：在考慮微調模型之前，應先嘗試進階的提示技巧（如提供上下文、範例、思路鏈提示），通常更簡單有效。

**Vertex AI 中嵌入模型的監督式微調 (Supervised Fine-tuning)**：

- **可用類型**：截至錄製時，Vertex AI **僅支援嵌入模型的監督式微調**（未提供基於人類回饋的強化學習 RLHF）。
- **目的**：透過使用帶有標籤的範例來「教導」模型，使其生成的嵌入向量能**更準確地反映特定領域或任務中所需的相似性關係**，模仿範例中展示的輸出模式。
- **機制**：在原始基礎模型之上學習**額外的參數（層）**，形成一個**新的、經過調整的模型**。原始的基礎模型本身不受影響。
- **支援的模型（截至錄製時）**：包括 `text-bison`, `chat-bison`, `code-bison`, `codechat-bison` 以及本課程重點 **`textembedding-gecko`**。
- **微調後嵌入的變化**：
    - 向量中的數值會與原始基礎模型產生的略有不同。
    - **與嵌入適配器 (Embedding Adapters) 的比較**：
        - **相似目標**：都是調整向量在空間中的位置以獲得更相關的結果。
        - **主要區別**：嵌入適配器**只調整查詢向量**；而模型微調則是調整模型本身，使得**所有**由這個微調後模型產生的嵌入向量（包括查詢和文件）都可能在向量空間中處於更佳的位置，以反映特定任務的相似性需求。

**Vertex AI 上的監督式模型調整工作流程：**

1. **準備模型調整資料集**：
    - **核心**：需要一組帶有標籤的範例，包含查詢、相關文件以及它們之間的相關性分數。
    - **所需檔案（上傳至 Cloud Storage）**：
        - **語料庫文件 (Corpus File - `corpus.jsonl`)**：包含實際的文件內容（例如：`id`, `title`, `text`）。JSONL 格式，每行一個 JSON 物件。
        - **查詢文件 (Query File - `queries.jsonl`)**：包含代表性的使用者查詢（例如：`query_id`, `text`）。若無真實資料，可請 LLM 生成。
        - **訓練標籤 (Train Labels - `train.tsv`)**：一個 **TSV (Tab 分隔)** 檔案，包含 `(查詢 ID, 文件 ID, 相關性分數)`。分數是**正數**，數值越大代表越相關（不同於嵌入適配器用的 +/- 1）。分數可來自使用者回饋、人工標註或 LLM 標註。
        - **測試標籤 (Test Labels - `test.tsv`)**：格式與訓練標籤相同，用於評估微調後模型的準確性是否提升。
2. **建立監督式調整作業 (Supervised Tuning Job)**：
    - 使用 **Vertex AI Pipelines** 啟動一個新的微調作業。
    - 將作業指向 Cloud Storage 中的資料集。
3. **獲取調整後的模型**：
    - 調整作業完成後，新的、經過調整的模型會出現在 **Vertex AI Model Registry** 中。

**部署與使用調整後的嵌入模型：**

- **管理責任**：與基礎模型不同，**調整後的模型是由使用者管理的**。
- **資源配置**：需要自行管理部署所需的資源，如機器類型和加速器 (GPU)。
- **建議配置**：建議使用 **`NVIDIA_TESLA_A100`** GPU 類型進行部署，以支援最大批次大小（batch size=5）和任意輸入長度，防止記憶體不足錯誤。
- **限制**：調整後的模型仍然有輸入 Token 限制（例如 `textembedding-gecko` 是 3072），過長輸入會被截斷。
- **使用方法**：
    - 在呼叫嵌入 API 時，指定使用你**調整後模型的名稱**（例如 `"custom-financial-embeddings-model"`）。
    - **舉例**：`model = TextEmbeddingModel.from_pretrained("custom-financial-embeddings-model")`
    - 之後以相同方式呼叫 `get_embeddings()` 等方法，即可獲得針對你的特定需求優化過的嵌入向量。

**總結：**

透過 Vertex AI 的監督式微調功能（屬於 PEFT），可以利用標註好的特定領域或任務數據（查詢、文件、相關性分數），來調整像 `textembedding-gecko` 這樣的基礎嵌入模型。這會產生一個新的、客製化的模型，其生成的嵌入向量更能反映特定應用所需的語意相似性，有助於顯著提升 RAG 系統的檢索相關性。相較於嵌入適配器（僅調整查詢），模型微調能更全面地優化嵌入空間。使用者需要準備特定格式的資料集，並自行管理調整後模型的部署。