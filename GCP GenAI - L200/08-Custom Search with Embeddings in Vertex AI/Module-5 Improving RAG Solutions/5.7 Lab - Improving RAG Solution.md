# 8.5.7 Lab - Improving RAG Solution

這個 Lab 就是實作前面幾個章節提到的 Solution，除了 Fine Tuning 以外的三種方式。使用的檔案是 2022 alphabet 的年報檔，然後透過一些 LangChain 的工具把這個 PDF 檔進行切成多個 chunk，然後又進行每 256 個 Token 再進行切割。

好了之後分別把每個 Chunk 的 Embedding 存進 chromadb 這個向量資料庫，然後就可以 chromadb 內建的 query method 來 retrieve 資料，也可以指定要取得最相關的幾筆，然後把 retrieve 的結果放到 LLM 的 Prompt 就完成了 RAG 的流程。

接著 Lab 試著把每個 chunk 的 Data 用 2D 的方式顯示出來，然後輸入不同 Query 把 retrieve 的 Data 給標示出來。可以發現如果是問到有相關的問題，那麼 retrieve 的 Data 也都互相會很近，但是如果問一個不相關的問題的話，那麼互相就都會距離很遠。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/17436899550009ofa1f.png)

## Query Augmentation

接下來要嘗試 Query augmentation 這個方式，這是使用 AI 幻覺產生出的可能解答來進行 Query augmentation，以便為向量查詢提供更多的 context，然後用原本的 query 加上 AI 生成的那些可能的回覆變成新的 query 內容，下圖是 retrieve 的結果，紅色是原始的 query，橘色是新的 query，選擇的答案更接近 augmented query 數據點。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/17436902410008k3s2d.png)

接下來換成擴充更多的 query，也就是透過 AI 生成跟 query 有相關的類似問題，然後與原 query 組合成新的 query。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1743690424000ttc0xj.png)

## Re-ranking results

透過使用 `cross-encoder/ms-marco-MiniLM-L-6-v2` cross-encoder 模型的方式，將第一次 retrieve 的結果與原始的 query 重新計算相似性，並重新給定一個分數然後重新排列，取得重新排列後的 retrieve data。

## Embedding Adapters

首先生成可能要求財務報表的查詢，因為這個 Lab 是用於查詢 Alphabet 財報的實作，所以查詢問題都會跟財務報表有相關。接著由模型來評估 query 跟 retrieve 的結果有沒有相關，有的話就是 yes，沒有的話就是 no，用這個方式區分相關和不相關的 retrieve。

1. **產生訓練資料 (Generate Training Data)**
    
    - **產生查詢 (`generate_queries`)**: 首先，它使用一個大型語言模型 (LLM，如 Gemini) 來模擬使用者可能會問的、與分析年報相關的問題 (10-15個)。這一步模擬了真實世界的使用者查詢。(如果已有真實使用者查詢紀錄，則可直接使用。)
    - **初步檢索 (`chroma_collection.query`)**: 使用這些生成的查詢，去先前建立好的 ChromaDB 向量資料庫中搜尋，找出每個查詢最相似的前 10 個文件區塊 (`retrieved_documents`) 及其嵌入向量 (`retrieved_embeddings`)。
    - **獲取查詢嵌入 (`embedding_function(generated_queries)`)**: 同時，也需要得到這些生成查詢本身的嵌入向量 (`query_embeddings`)。
    - **標註相關性 (`evaluate_results`)**: **這是監督學習的關鍵**。對於每個查詢 (`query`) 和它檢索到的每個文件區塊 (`document`)，再次呼叫 LLM 來判斷這個文件區塊對於該查詢是否「相關」。LLM 被指示只輸出 'yes' 或 'no'，函數接著將其轉換為數值標籤：相關 (`yes`) 為 `1`，不相關 (`no`) 為 `-1`。
    - **整理成對資料**: 將查詢嵌入、對應的文件嵌入、以及它們之間的相關性標籤 (1 或 -1) 一一對應起來，分別存入 `adapter_query_embeddings`, `adapter_doc_embeddings`, `adapter_labels` 這三個列表中。這樣就構成了一系列的 (查詢向量, 文件向量, 相關性標籤) 訓練樣本。
2. **設定 PyTorch 環境 (Setup PyTorch Environment)**
    
    - **安裝 PyTorch (`pip install torch`)**: 確保環境中有 PyTorch 函式庫。
    - **轉換為 Tensor**: 將前面準備好的 Python 列表（嵌入向量和標籤）轉換成 PyTorch 的 Tensor 格式，這是 PyTorch 進行計算的基本單位。注意標籤 `adapter_labels` 被擴展了一個維度 (`np.expand_dims`) 以符合 PyTorch 損失函數的期望格式。
    - **建立 Dataset**: 使用 `torch.utils.data.TensorDataset` 將查詢嵌入、文件嵌入和標籤打包成一個 PyTorch 資料集物件，方便後續的訓練迴圈讀取。
3. **定義 Adapter 模型與損失函數 (Define Model and Loss)**
    
    - **模型函數 (`model`)**: 這個函數定義了 Embedding Adapter 的核心邏輯。
        - 輸入：原始查詢嵌入、文件嵌入、以及要學習的 `adaptor_matrix`。
        - 運算：`updated_query_embedding = torch.matmul(adaptor_matrix, query_embedding)`，這裡透過**矩陣乘法**將原始查詢嵌入乘以適配器矩陣，得到一個**轉換後 (adapted)** 的查詢嵌入。
        - 輸出：計算**轉換後的查詢嵌入**與**文件嵌入**之間的**餘弦相似度 (cosine similarity)**。訓練的目標是讓相關對 (label=1) 的相似度趨近於 1，不相關對 (label=-1) 的相似度趨近於 -1。
    - **損失函數 (`mse_loss`)**: 使用**均方誤差 (Mean Squared Error, MSE)** 來計算模型輸出的餘弦相似度與目標標籤 (1 或 -1) 之間的差距。訓練過程就是要最小化這個差距（損失）。
4. **初始化與訓練 Adapter 矩陣 (Initialize and Train)**
    
    - **初始化矩陣 (`adapter_matrix`)**: 建立一個大小為 `mat_size x mat_size`（`mat_size` 是嵌入向量的維度）的方陣，用隨機數初始化。`requires_grad=True` 告訴 PyTorch 需要計算這個矩陣的梯度以便進行訓練。這個 `adapter_matrix` 就是我們要學習的「轉換器」。
    - **訓練迴圈**: 進行 100 次迭代 (epoch)。
        - 在每次迭代中，遍歷 `dataset` 中的每一對 (查詢嵌入, 文件嵌入, 標籤)。
        - 計算當前 `adapter_matrix` 下的損失 `loss`。
        - 記錄下產生最小損失 `min_loss` 時的矩陣狀態 `best_matrix`。
        - `loss.backward()`: 計算損失相對於 `adapter_matrix` 的梯度。
        - `with torch.no_grad(): ...`: 在更新權重時暫時關閉梯度計算。
        - `adapter_matrix -= 0.01 * adapter_matrix.grad`: 根據計算出的梯度，使用**梯度下降法**更新 `adapter_matrix`。`0.01` 是學習率 (learning rate)。目標是讓矩陣朝著減少損失的方向進行微小的調整。
        - `adapter_matrix.grad.zero_()`: 清除梯度，為下一次迭代做準備。
    - **訓練解釋**: 這段訓練過程的白話解釋是：反覆調整 `adapter_matrix` 這個「濾鏡」，目標是讓經過這個濾鏡轉換後的查詢向量，在與文件向量計算餘弦相似度時，其結果能盡量接近我們標註的相關性分數 (1 或 -1)。
5. **評估與視覺化 (Evaluate and Visualize)**
    
    - **印出損失**: 顯示訓練過程中找到的最小損失值，表示模型學習到的最佳程度。
    - **創建縮放向量並繪圖 (Create scaled vector...)**: 這部分似乎是透過將學習到的 `best_matrix` 乘以一個全一向量來觀察矩陣對各個維度的整體縮放影響，並用長條圖展示。這可能是一種特定的分析方法，用來理解 adapter 大致增強或減弱了哪些維度。
    - **獲取適配後的查詢嵌入**: 使用學習到的 `best_matrix` 透過矩陣乘法 (`np.matmul`) 實際轉換**原始**的 `generated_queries` 的嵌入向量，得到 `adapted_query_embeddings`。
    - **降維投影 (`project_embeddings`)**: 使用 UMAP (或其他降維方法，這裡假設是 `project_embeddings` 函數實現的) 將**原始查詢嵌入**和**適配後的查詢嵌入**都投影到二維空間，以便視覺化。
    - **繪製比較圖**: 繪製散點圖：
        - 用灰色點表示背景資料集（文件）的嵌入。
        - 用紅色 X 表示**原始**查詢嵌入的投影位置。
        - 用綠色 X 表示**經過 adapter 轉換後**的查詢嵌入的投影位置。
        - 這張圖就是你上次提供的那張 "Adapted Queries" 圖，它直觀地展示了 embedding adapter 對查詢向量位置的影響。

**總結：**

這整段程式碼演示了一個完整的 embedding adapter 訓練流程：首先透過 LLM 輔助生成查詢和標註相關性來創建訓練資料，然後使用 PyTorch 定義 adapter 模型（一個轉換矩陣）和損失函數，接著透過梯度下降法訓練這個矩陣，使其能夠優化查詢嵌入，最後透過視覺化展示 adapter 對查詢嵌入位置的影響。目標是提升向量搜尋在特定領域和查詢類型下的相關性排序能力。下圖可以看到 adapter 後的結果明顯是更加的集中。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/174369131000029e9m7.png)
