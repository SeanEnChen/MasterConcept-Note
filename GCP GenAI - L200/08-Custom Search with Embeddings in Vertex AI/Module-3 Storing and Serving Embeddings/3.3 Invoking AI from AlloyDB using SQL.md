# 8.3.3 Invoking AI from AlloyDB using SQL

**核心目標：展示如何利用 AlloyDB 的整合功能，直接透過 SQL 指令呼叫部署在 Vertex AI 上的機器學習模型進行預測，無需手動建立複雜的整合流程。**

**前置作業與設定：**

1. **準備環境**：
    - 需要一個 AlloyDB for PostgreSQL 叢集。
    - 需要一個 Vertex AI 專案，並且已經部署好一個可用的預測端點（範例中使用的是「詐欺偵測」模型端點）。
2. **授予權限 (IAM)**：
    - 必須讓 AlloyDB 叢集有權限呼叫 Vertex AI 服務。
    - **步驟**：
        - 取得 AlloyDB 所在的 Google Cloud 專案編號 (Project Number)。
        - 前往**部署 Vertex AI 端點**的那個專案的 IAM 頁面。
        - 新增一個主體 (Principal)，格式通常類似 `service-[AlloyDB專案編號]@gcp-sa-alloydb.iam.gserviceaccount.com`（請參考官方文件確認最新格式）。
        - 指派角色 (Role) 給這個主體：選擇 **`Vertex AI User`** 角色。
        - 儲存設定。（可能需要勾選「包含 Google 提供的角色授權」才能看到剛新增的主體）。
3. **取得端點詳細資訊**：
    - 前往 Vertex AI 的「端點 (Endpoints)」頁面，找到你的目標端點（如：詐欺偵測端點）。
    - 點擊「範例請求 (Sample Request)」。
    - 記下 **端點 ID (Endpoint ID)**、**專案 ID (Project ID)** 以及端點部署的**區域 (Region)**（例如 `us-central1`）。

**從 AlloyDB SQL 呼叫預測的步驟：**

1. **連接資料庫**：使用 SQL 客戶端（如 `psql` 或範例中的 `pgcli`）連接到 AlloyDB 的主實例 (Primary Instance) 和目標資料庫。
2. **準備資料表**：確保 AlloyDB 中有包含需要進行預測的資料的表格（例如 `fraud_detection_data` 表，包含交易時間、金額及 V1, V2 等特徵欄位）。
3. **啟用擴充功能**：在 AlloyDB 中執行 SQL 指令，安裝 Google 提供的 Vertex AI 整合擴充功能（假設名稱為 `google_vertex_ai`）：
4. **使用預測函數**：利用該擴充功能提供的函數（例如 `google_vertex_ai.ml_predict_row()`）來呼叫 Vertex AI 端點。
    - **函數參數**：
        - `endpoint`：一個字串，包含之前記下的專案 ID、區域、端點 ID，需按特定格式組合。
        - `instance`：一個 JSON 物件，代表**單筆**要預測的資料。通常使用 `row_to_json(表格別名)` 將資料表的一行轉換成所需的 JSON 格式。
        - `parameters`：（可選）傳遞給模型的其他參數（範例中未使用）。
    - **解析回傳結果**：此函數會回傳一個 JSON 物件。預測結果通常在 `predictions` 這個鍵 (key) 底下。需要使用 JSON 處理函數（如 `->`）來提取所需的分數。

**範例一：逐行預測 (Row-by-Row)**

- **運作方式**：這個查詢會**為每一行資料發送一次** API 請求到 Vertex AI（在此例中是 500 次請求）。
- **結果解讀**：回傳的 `fraud_scores` 是一個 JSON，可能包含不同類別的預測分數。例如 `[0.99, 0.01]` 代表模型預測類別 0（非詐欺）的機率是 0.99，類別 1（詐欺）的機率是 0.01，因此判斷為非詐欺。反之 `[0.1, 0.9]` 則判斷為詐欺。
- **效能**：對於大量資料，這種方式較慢（範例中 500 行約需 14.5 秒）。

**範例二：批次預測 (Batch Prediction) 以提高吞吐量**

- **目的**：在**單一** API 請求中發送**多行**資料給 Vertex AI，以大幅提升處理速度。
- **方法**：利用 SQL 的彙總函數 `jsonb_agg()` 和 `GROUP BY` 子句。
    1. 先將多行資料（例如，隨機分成幾個批次）使用 `row_to_json()` 轉換後，再用 `jsonb_agg()` 彙總成一個 **JSON 陣列**。
    2. 呼叫 `ml_predict_row()` 時，將這個 JSON 陣列放在 `instances` 鍵的值裡面，形成一個批次請求的 JSON。
    3. Vertex AI 會回傳一個包含多個預測結果的陣列。
    4. 需要使用 `UNNEST` 和 `JSON_ARRAY_ELEMENTS` 等函數將回傳的批次結果**解開 (Unpack)**，並與原始的行對應起來。
- **效能**：顯著提升（範例中提到約 **21 倍**的改進）。效能提升程度取決於網路延遲、批次大小、平行處理能力等因素。

**總結：**

AlloyDB for PostgreSQL 透過 `google_vertex_ai` 擴充功能，提供了直接從 SQL 查詢中呼叫 Vertex AI 預測端點的強大整合能力。雖然可以逐行呼叫，但為了獲得更好的效能處理大量資料時，利用 SQL 的彙總功能將多筆資料**批次化 (Batching)** 後再送出單一請求是關鍵的優化手段。