# 8.3.5 Lab - Streaming Updates into Vertex AI Vector Search

第一步是先確認 `Service Networking API` 已經啟用。接著，在 Vertex AI Workbench 的 Jupyter Lab 環境中，我們透過 `gcloud` 指令預留一段名為 `cym-range` 的 IP 位址範圍，這個範圍是特別為了 VPC 網路對等互連 (VPC Peering) 而保留的 (`--purpose=VPC_PEERING`)。隨後，利用 `gcloud services vpc-peerings connect` 指令，將我們專案 (`qwiklabs-gcp-03-1618d94609fe`) 中的 `default` VPC 網路與 Google 的服務網路 (`servicenetworking.googleapis.com`) 建立起對等互連關係。這個網路設定是為了後續建立的 `IndexEndpoint` 能在私有環境中運行，提供安全的內部存取。

```Python
PROJECT_ID = "qwiklabs-gcp-03-1618d94609fe"
NETWORK_NAME = "default"
PEERING_RANGE_NAME = "cym-range"

# Reserve IP range
! gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={NETWORK_NAME} --purpose=VPC_PEERING --project={PROJECT_ID} --description="peering range for cymbal demo"

# Set up peering with service networking
! gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={NETWORK_NAME} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}
```

網路基礎打好後，就進入了資料準備階段。安裝必要的 Python 套件，在 Google Cloud Storage (GCS) 上建立一個儲存桶 (bucket) 來存放向量資料，並設定好相關的環境變數（如 Project ID、Region 等）。實驗中，我們載入了 GloVe 資料集，選取其中 100 筆資料，將它們的向量表示轉換為 JSON 格式，最後將這個 JSON 檔案上傳到前面建立的 GCS 儲存桶中，作為建立索引的資料來源。

有了資料源，接下來就是建立向量索引 `Index` 本身。我們會定義這個近似近鄰 (ANN) 索引的配置，包括向量維度、距離計算方式、使用的演算法等等，然後提交請求讓 Vertex AI 開始建立這個索引結構。索引 `Index` 本身只是儲存和組織資料的地方，我們還需要一個服務入口來接收查詢請求。這個 `IndexEndpoint` 會利用先前設定好的 VPC Peering 網路，確保查詢服務運行在私有網路中。最後，也是讓整個系統能運作起來的關鍵整合步驟，這個部署動作將我們建立好的索引 `Index` 資料結構連接到查詢服務端點 `IndexEndpoint`。完成部署後，系統就準備好接收查詢了。

> [!note]
> 1. 準備好你的向量資料。
> 2. 建立 `Index`，讓 Vertex AI 把你的向量組織成可快速搜尋的結構。
> 3. 建立 `IndexEndpoint`**，作為你的應用程式查詢的入口。**
> 4. 把 `Index` 部署到 `IndexEndpoint`** 上。
> 5. 應用程式向 `IndexEndpoint` 發送查詢，`IndexEndpoint` 利用部署好的 `Index` 找到結果並回傳。
> 
> 它們是分工合作的關係，一個負責儲存和結構化資料，另一個負責提供查詢服務。

完成部署後，整個系統就緒，可以開始進行此實驗的核心內容：透過 gRPC 與部署好的索引 `Index` 互動，執行查詢並進行即時更新。為了能與這個部署好的索引溝通，我們需要先定義好通訊的規則。這透過建立一個 `match_service.proto` 檔案來完成，它詳細定義了 `MatchService` 服務、`Match` 方法以及請求 (`MatchRequest`) 和回應 (`MatchResponse`) 的資料結構，包括查詢向量、期望鄰居數量、目標索引ID，甚至還有進階的篩選 (`restricts`) 和多樣性控制 (`crowding`) 參數。接著，我們需要下載一些 Google API 的通用定義檔 (`git clone ...googleapis.git`)，然後使用 `protoc` 工具將 `.proto` 檔案編譯成 Python 程式碼 (`match_service_pb2.py`, `match_service_pb2_grpc.py`)，這樣我們的 Python 應用程式才能方便地建立請求、解析回應。同時，我們需要取得先前部署索引時產生的私有端點 IP 位址 (`DEPLOYED_INDEX_SERVER_IP`)，這是我們建立 gRPC 連線的目標地址，確保通訊在安全的 VPC 內部進行。

1. **定義 gRPC 服務契約 (`match_service.proto`)**
    
    - 這一步是定義客戶端（你的程式碼）和 Vertex AI 向量搜尋後端服務之間如何溝通。
    - 它定義了一個叫做 `MatchService` 的服務，裡面有一個 `Match` 方法，用來執行相似度搜尋。
    - 同時定義了請求 (`MatchRequest`) 和回應 (`MatchResponse`) 的詳細格式：
        - `MatchRequest`：包含你要查詢的向量 (`float_val`)、要找幾個鄰居 (`num_neighbors`)、要查詢哪個已部署的索引 (`deployed_index_id`)，以及一些進階選項，如**篩選 (filtering)** (`restricts`) 和**結果多樣性控制 (crowding)** (`per_crowding_attribute_num_neighbors`) 等。
        - `MatchResponse`：包含找到的鄰居列表，每個鄰居有其 ID (`id`) 和距離 (`distance`)。
2. **準備 gRPC 相關程式碼**
    
    - `git clone ...googleapis.git`：下載 Google API 的通用定義檔，因為 `match_service.proto` 可能會用到裡面的一些標準定義。
    - `python -m grpc_tools.protoc ...`：**編譯 `.proto` 檔**。這會自動產生兩個 Python 檔案 (`match_service_pb2.py` 和 `match_service_pb2_grpc.py`)。這些檔案包含了你在 Python 中建立請求物件、解析回應物件以及呼叫遠端 gRPC 服務所需的類別和函式。
3. **取得私有端點 IP 位址 (`DEPLOYED_INDEX_SERVER_IP`)**
    
    - 你的 `Index` 部署到 `IndexEndpoint` 後，會獲得一個**私有的 IP 位址**，用於在你的 VPC 網路內部進行 gRPC 通訊（這樣更安全、延遲更低）。這行程式碼就是去查詢這個 IP 位址。
4. **建立 gRPC 連線並測試基本查詢**
    
    - 使用 `grpc.insecure_channel` 連接到上一步取得的 IP 位址和指定埠號 (10000)。
    - 建立 `MatchServiceStub`，這就是你可以用來呼叫 `Match` 方法的客戶端物件。
    - 準備一個查詢向量 (`query`)。
    - 建立 `MatchRequest` 物件，填入部署的索引 ID (`DEPLOYED_INDEX_ID`) 和查詢向量 (`query`)。
    - 呼叫 `stub.Match(request)` 發送請求並接收回應。
    - **目的**：驗證基本的查詢功能是否正常，看看針對 `query` 向量能找到哪些最相似的鄰居。
5. **展示串流更新 (Stream Update) - 新增資料點 (`Insert datapoints`)**
    
    - 這裡使用了另一個 Vertex AI 的客戶端 (`index_client`)，這次是**管理索引本身**的。
    - 建立一個 `IndexDatapoint` 物件，包含新的 ID ("101")、特徵向量 (用的是跟剛才查詢相同的向量)、以及一些元資料 (用於篩選的 `restricts` 和用於多樣性的 `crowding_tag`)。
    - 呼叫 `index_client.upsert_datapoints` 將這個新的資料點**插入**到索引中 (因為你的索引設定了 `STREAM_UPDATE`)。
    - **再次執行**和第 4 步相同的查詢。
    - **目的**：展示索引可以即時更新。因為新插入的點向量和查詢向量相同，所以在第二次查詢結果中，你應該會看到 ID 為 "101" 的這個點，且距離非常接近 0。
6. **展示查詢時加入篩選 (`Add filtering`)**
    
    - 建立 `MatchRequest`，除了查詢向量外，還額外加入了 `restricts` 條件。
    - 這個條件 (`Namespace(name="class", allow_tokens=["1", "101"])`) 要求只在 `class` 這個命名空間中，允許的 token 是 "1" 或 "101" 的那些資料點裡進行搜尋。
    - 執行查詢。
    - **目的**：展示如何在查詢時根據元資料進行過濾，只搜尋符合特定條件的子集。結果應該只包含 ID 為 "1" 和 "101" (如果它們存在且相似的話) 且符合 "class" 條件的鄰居。
7. **展示串流更新 - 更新資料點的篩選條件 (`Update datapoint filtering`)**
    
    - 再次呼叫 `index_client.upsert_datapoints` 來**更新** ID 為 "101" 的資料點。
    - 這次主要是修改它的 `restricts`，將其 `allow_list` 改為 `["102"]`。
    - **再次執行**和第 6 步相同的**帶有篩選條件**的查詢 (篩選條件仍然是允許 "1" 和 "101")。
    - **目的**：展示可以即時更新資料點的元資料。因為 "101" 的 `allow_list` 被改成了 "102"，它不再符合查詢中 `allow_tokens=["1", "101"]` 的條件，所以這次查詢結果中應該**不會**再看到 "101" 了。
8. **展示查詢時加入結果多樣性控制 (`Add crowding`)**
    
    - 建立 `MatchRequest`，除了查詢向量外，還設定了 `per_crowding_attribute_num_neighbors = 1`。
    - 執行查詢。
    - **目的**：展示 Crowding 功能。這個設定告訴系統，對於具有相同 `crowding_attribute` 的資料點，最多只返回 1 個（最相似的那個）。這有助於避免搜尋結果被某個類別或屬性的資料點霸佔，讓結果更多樣化。
9. **展示串流更新 - 更新資料點的 Crowding 標籤 (`Update datapoint crowding`)**
    
    - 再次呼叫 `index_client.upsert_datapoints` 來**更新** ID 為 "101" 的資料點。
    - 這次主要是修改它的 `crowding_tag`，將 `crowding_attribute` 從之前的 "b" 改為 "a"。
    - **再次執行**和第 8 步相同的**帶有 Crowding 限制**的查詢。
    - **目的**：展示可以即時更新資料點的 Crowding 屬性。由於 "101" 現在屬於不同的 Crowding 群組 ("a")，這可能會影響第 8 步的查詢結果（例如，如果之前有另一個屬於 "a" 群組的點比 "101" 更近，那麼 "101" 可能就不會出現；或者如果 "101" 是 "a" 群組裡最接近的，它現在可能會出現）。
10. **展示串流更新 - 刪除資料點 (`Remove datapoints`)**
    
    - 呼叫 `index_client.remove_datapoints`，明確要求從索引中刪除 ID 為 "101" 的資料點。
    - **再次執行**和第 4 步相同的**基本查詢**（無篩選、無 Crowding）。
    - **目的**：展示可以即時從索引中刪除資料點。"101" 這個點應該從查詢結果中消失了。

**總之，這整段程式碼是一個完整的範例，展示了如何：**

1. **設定 gRPC 連線** 到部署好的 Vertex AI 向量搜尋索引端點。
2. 執行**基本的相似度查詢**。
3. 利用索引的**串流更新**能力，即時地**新增、更新（包括元資料如篩選條件和 Crowding 標籤）、刪除**索引中的資料點。
4. 在查詢時使用**篩選 (`restricts`)** 和**結果多樣性控制 (`crowding`)** 等進階功能。