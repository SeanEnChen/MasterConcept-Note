# 6.6.5 Prompt tuning deep-dive

**Prompt Tuning (提示調整) 概觀**

- **核心機制**：此方法的核心是訓練一個「軟提示 (soft prompt)」。這個軟提示**不是**一串文字指令，而是**一組可訓練的嵌入向量 (embedding vectors)**。這些向量會被添加（原文提到 appended/suffix，但通常實作是加在前面 prepend）到輸入文本轉換成的嵌入向量序列中。
    - **重要區別**：我們訓練的是**嵌入向量本身**（一堆數字），而不是文字符號 (tokens)。
- **維度**：這些軟提示向量的維度（大小）與模型中用於表示一般文字符號的嵌入向量維度**相同**。例如，如果模型使用 1024 維的嵌入向量，那麼軟提示中的每個向量也是 1024 維。
- **發生時間點**：軟提示是在輸入文字被轉換成嵌入向量**之後**才加入的。

**主要優點**

1. **極高的參數效率**：
    - 軟提示通常非常小。實驗表明，即使只用**一個**軟提示向量（例如，如果嵌入維度是 4096，那也只需要訓練約 4000 個參數），對於大型模型來說，在很多任務上已經能激發出良好的反應。
    - 因為只訓練和儲存這些極小的軟提示，而**不需要**更新或儲存數十億參數的基礎模型副本。這與傳統微調 (fine-tuning) 需要為每個任務儲存整個模型（可能幾 GB 大小）形成鮮明對比。
	
2. **高效的批次推論 (Batch Inference)**：
    - 在推論（模型預測）階段，可以在**同一個批次 (batch)** 中混合來自**不同任務**的輸入，每個輸入搭配其對應的軟提示。
    - **舉例**：你可以將「任務A的輸入 + 軟提示A」和「任務B的輸入 + 軟提示B」放在同一個批次裡，讓模型一次處理，提高效率。雖然不是真正的平行處理任務，但批次處理效率很高。
	
3. **支持集成式推論 (Ensemble Inference)**：
    - 可以為**同一個任務**訓練出**多個不同**的軟提示。
    - **舉例**：針對「情感分析」任務，你可以訓練出 3 個不同的軟提示（P1, P2, P3）。在推論時，將同一個輸入評論分別與 P1, P2, P3 結合，在一個批次中得到 3 個結果，然後可以將這些結果平均、投票或選擇最好的，來提升最終的預測效果。

**性能表現**

- **效果優異**：在許多單任務和多任務場景下，Prompt Tuning 的性能可以**媲美**對整個模型進行微調 (full model tuning)。
- **依賴模型規模**：Prompt Tuning 的效果**隨著基礎模型規模的增大而提升**。對於較小的模型，效果可能沒那麼顯著；但對於大型模型，它非常有效。
    - **實驗背景**：該論文的實驗主要基於 T5 模型。小型模型指 T5 Base（數億參數），大型模型指 T5 XXL（110 億參數）。
    - **未來展望**：預期在目前更大（如 Vertex AI 上的 240 億參數）的模型上，Prompt Tuning 會有非常好的表現。
- **與 GPT-3 對比**：在論文的實驗中，使用 Prompt Tuning 的 T5 XXL (11B) 在許多任務上的表現，甚至**優於**使用「情境學習 (in-context learning)」的 GPT-3 (175B)。

**軟提示的初始化**

- **重要性**：如何設定軟提示向量的初始值是一個關鍵決策。
- **方法**：
    - 隨機初始化。
    - 從模型**詞彙表中真實詞彙**的嵌入向量來初始化。
    - 對於分類任務，可以從**類別標籤 (class labels)** 的嵌入向量來初始化（例如，用 "positive", "negative" 對應詞彙的嵌入向量）。
- **影響**：初始化方法對**小型模型**影響較大（例如，用詞彙表初始化通常優於隨機初始化）。但隨著模型規模的增大，不同初始化方法之間的差異會逐漸縮小。

總之，Prompt Tuning 是一種非常參數高效的方法，透過學習少量的嵌入向量（軟提示）來引導大型預訓練模型適應新任務，同時保持模型主體不變，並在性能和推論效率上展現出諸多優勢，特別適合大型模型。

> [!note]
> 「Prompt Tuning」這個名字裡的 **"Tuning" (調整/微調)** ，指的就是**學習和優化**那一組「軟提示」向量（也就是我們比喻的「神祕調味粉」或「特殊訊號」裡面的那些數字向量）的過程。
> 
> 具體來說，在 Prompt Tuning 的訓練階段：
> 1. 一開始，這些軟提示向量可能是隨機的，或者用某些方法初始化的。
> 2. 模型會讀取訓練數據（例如，帶有情感標籤的句子）。
> 3. 將當前的軟提示向量加到輸入句子的嵌入向量前面，送入**凍結不動**的大模型。
> 4. 模型的輸出結果與正確答案差多少（計算損失）。
> 5. 根據這個誤差，**只去調整、修改那些軟提示向量裡面的數值**，讓它們下次能更好地引導模型做出正確的輸出。
> 6. 不斷重複這個過程，直到找到一組效果最好的軟提示向量。
> 
> 所以，整個「Tuning」的過程，就是**專注於把這一小組軟提示向量「調」到最佳狀態**，而不是去「調」那個巨大的模型本身。這就是它和傳統的「Fine-Tuning」（微調模型本身參數）最大的不同。


