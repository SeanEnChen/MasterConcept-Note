# 6.6.3 Overview of PEFT methods

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1743557838000q6mz1i.png)

**總結**: 這張圖片提供了一個清晰的視覺化分類，將 PEFT 的主要技術思路歸納為：修改模型結構加入小模組 (Model-Level: Adapter)、在輸入端加入可學習的提示 (Feature-Level: Prompt-Tuning)、用少量參數表示對現有權重的更新 (Parameter-Level: LoRA, Diff-Pruning)、或只更新現有參數中極小的一部分 (Partial Fine-tuning: BitFit)。理解這些分類有助於掌握不同 PEFT 方法的核心差異與應用方式。

1. **模型級別 (Model-Level) - 適配器微調 (Adapter-Tuning)**
    - **機制**：這類方法透過在預訓練模型的 **現有架構中插入新的、小的模組** 來進行微調。圖片中清楚地展示了 "Adapter" 模組被插入到 Transformer Block 中的多頭注意力 (Multi-Head Attention) 層和前饋網路 (Feed Forward) 層之後、Add & Norm 層之前的位置。這符合先前描述的「架構修改型」思路。
    - **訓練對象**: 只訓練這些 **新加入的 Adapter 模組** 的參數，原始模型的大部分參數保持凍結。
    - **例子情境**：假設一家大型企業使用一個通用的預訓練語言模型（例如 BERT 或 GPT）來處理客戶服務的郵件。他們希望這個模型能同時處理多種任務，例如：(1) 將郵件分類（投訴、詢問、感謝），(2) 從郵件中提取關鍵資訊（訂單號、問題點），(3) 生成標準回覆的草稿。
    - **應用 Adapter-Tuning**：他們可以保持巨大的基礎模型參數不變。
        - 對於**分類任務**，他們在基礎模型的每一層插入「分類 Adapter」，並只用標註好的分類郵件來訓練這些 Adapter。
        - 對於**資訊提取任務**，他們插入並訓練另一組「提取 Adapter」。
        - 對於**回覆生成任務**，他們再插入並訓練第三組「生成 Adapter」。
    - **好處**：只需要儲存一個大型基礎模型和三組非常小的 Adapter 參數，就能讓同一個基礎模型高效地執行三種不同任務，大大節省了儲存空間和部署成本，相較於為每個任務都完整微調一個大模型。
	
2. **特徵級別 (Feature-Level) - 提示微調 (Prompt-Tuning)**
    - **機制**：這類方法 **不改變原始模型架構**，而是在 **輸入特徵層面** 加入額外的、可訓練的參數。圖片顯示，在原始的輸入嵌入 (Input Embedding) 旁邊，額外加入了一些代表 "Prompt" 的虛擬 Token 嵌入（圖中紫色方塊）。這些可學習的嵌入向量會影響模型的後續處理。這符合先前描述的「激活/嵌入添加型」思路。
    - **訓練對象**: 只訓練這些**新加入的 Prompt 嵌入向量**
    - **例子情境**：一個新聞機構想要使用一個超大型語言模型（例如 GPT-4）來自動生成不同風格的新聞摘要，例如：(1) 非常簡短的快訊風格，(2) 較為詳細的分析風格。
    - **應用 Prompt-Tuning**：他們凍結 GPT-4 的所有參數。
        - 對於 **快訊風格**，他們設計一組可訓練的「快訊 Soft Prompt」（例如 10 個虛擬 token）。他們用「長篇新聞 -> 快訊摘要」的範例來訓練這 10 個 token 的嵌入向量。
        - 對於 **分析風格**，他們設計並訓練另一組「分析 Soft Prompt」。
    - **好處**：訓練完成後，只需要在輸入的長篇新聞前加上對應訓練好的 Soft Prompt（例如「快訊 Soft Prompt」 + 新聞原文），那個被凍結的 GPT-4 就能生成相應風格的摘要。這比為每種風格都完整微調模型要高效得多，而且只需要學習和儲存非常少的 Prompt 參數。
	
3. **參數級別 (Parameter-Level) - LoRA (Low-Rank Adaptation)**
	- **機制**: 這類方法同樣 **不改變模型架構**，而是直接針對模型 **現有的參數** 進行高效的修改或添加更新量。
	    - **LoRA**: 圖片中視覺化為在原始權重（未直接畫出，但 LoRA 作用於其上）旁添加了兩個低秩矩陣 A 和 B。微調時只訓練這兩個小矩陣，它們的乘積代表了對原始權重的更新量。
	    - **Diff-Pruning**: 圖片中以 $δ_T$ 表示，暗示可能是計算和應用權重的「差值更新」或進行某種形式的稀疏化更新。
	    - 這兩者都屬於先前討論的「參數級別/權重修改型」範疇，著重於用少量參數來表示對大量現有參數的調整。
	- **訓練對象**: 這些用於表示更新量的少量參數（如 LoRA 的 A、B 矩陣）或特定的權重差值/子集。
    - **例子情境**：一位藝術家想使用圖像生成模型（例如 Stable Diffusion）來創作具有自己獨特繪畫風格的圖片。或者，一家遊戲公司想微調一個 LLM 來扮演他們遊戲世界觀中的特定角色，使其對話符合該角色的性格和背景知識。
    - **應用 LoRA**：
        - **藝術家**：凍結 Stable Diffusion 的主要模型權重。在模型的關鍵部分（如 Attention 層）注入 LoRA 的低秩矩陣 A 和 B。然後，只用這位藝術家自己風格的作品來訓練這些 A 和 B 矩陣。訓練好的 LoRA 文件（通常只有幾 MB 到幾十 MB）可以加載到原始 Stable Diffusion 模型上，生成具有其獨特風格的圖片。
        - **遊戲公司**：同樣凍結 LLM 的主要權重，注入 LoRA 矩陣，並只用符合該角色設定的對話資料來訓練 A 和 B 矩陣。之後，載入這個 LoRA 就能讓通用 LLM「扮演」好這個特定角色。
    - **好處**：訓練成本（尤其是顯存需求）遠低於完整微調，而且可以輕鬆切換或疊加不同的 LoRA 效果（例如一個 LoRA 控制風格，另一個 LoRA 控制內容主題）。
	
4. **部分微調 (Partial Fine-tuning) - BitFit**
	- **機制**: 這類方法也 **不改變模型架構**，但它的特點是只更新模型 **現有參數** 中一個預先定義好的、**非常小的子集**。圖片非常清晰地指出，BitFit **只更新模型中的偏置項 (Bias terms, $b_L$)**，而凍結其他所有參數（如主要的權重矩陣）。這可以看作是「參數級別/權重修改型」中的一種非常具體且簡潔的特例。
	- **訓練對象**: 僅模型中選定的參數子集，例如 BitFit 中的所有偏置項。
    - **例子情境**：需要對一個預訓練模型（如 BERT）做一個相對簡單的文本分類任務，例如判斷電影評論是正面還是負面。假設任務不複雜，且計算資源極度有限。
    - **應用 BitFit**：研究人員或工程師決定採用最極致的參數節省方式。他們凍結 BERT 模型中所有的主要權重矩陣（這些矩陣負責主要的語言理解和轉換），**只允許模型中的所有偏置項 (Bias terms) 在訓練過程中被更新**。他們使用標註好的電影評論數據來訓練這些 Bias 參數。
    - **好處**：更新的參數量達到了極小值（Bias 通常只佔總參數量的 0.1% 或更少），對硬體要求最低。雖然對於複雜任務效果可能不如其他 PEFT 方法，但在特定簡單任務或作為實驗基線時，提供了一種極端高效的可能性。