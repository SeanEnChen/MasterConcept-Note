# 6.6.6 Prompt tuning workflow

這段關於 Prompt Tuning 的補充資訊，包含預訓練目標和資料準備的影響：

**1. 預訓練目標對 Prompt Tuning 效果的影響**

- **核心發現**：研究者注意到，使用**標準語言模型 (Language Modeling, LM) 目標**（也就是預測**下一個字詞**，像 GPT 那樣）預訓練的模型，在使用 Prompt Tuning 時的效果，通常**優於**使用**遮蓋語言模型 (Masked Language Modeling, MLM) 目標**（也就是填空，像 BERT 或原始 T5 那樣）預訓練的模型。
- **實驗驗證**：
    - 研究人員拿了現有的 T5 模型檢查點（Checkpoints），這些模型主要是用 MLM 目標訓練的編碼器-解碼器架構。
    - 他們對這些 T5 模型進行了**額外的訓練**，採用了 LM 目標（預測下一個字詞），持續了大約十萬步（稱為「LM 適應」）。
    - 結果發現，這些**經過 LM 適應後的 T5 模型**，在使用 Prompt Tuning 時表現**更好**。
- **與現有模型的關聯**：
    - 目前在 Vertex AI 中的模型，如 Bison 系列（`text-bison`, `chat-bison`），據描述是僅解碼器 (decoder-only) 架構，並且是用 LM 目標訓練的。
    - 因此，這些模型**理論上應該非常適合**使用 Prompt Tuning。

**2. Prompt Tuning 的資料準備方式**

- **對比 T5 的標準做法**：
    - 原始 T5 模型在訓練時，通常會將不同的任務轉換成「文本到文本 (text-to-text)」的格式。
    - 一個常見的做法是在輸入序列的**最前面加上任務名稱**作為前綴。
    - **舉例**：對於 COPA（因果推理）任務，輸入序列會以 `copa:` 開頭，例如 `copa: [選項 A] 因為 [前提]，所以 [選項 B]`。
- **Prompt Tuning 的簡化做法**：
    - 在 Prompt Tuning 的實驗中，研究人員發現，雖然可以使用與 T5 相同的資料集準備方式，但可以**進一步簡化**。
    - 他們**移除了**輸入序列前面的**任務名稱前綴**（例如，不再需要加 `copa:`）。
- **原因**：
    - 因為「軟提示」本身（那一串學習到的嵌入向量）就已經在**引導或「調整」模型去執行特定的任務**了。
    - 軟提示已經包含了任務特定的信號，所以額外再用文字（如 `copa:`）告訴模型這是什麼任務，就變得**多餘或不必要**了。

**總結來說：**

- 預訓練時使用「預測下一個字詞」(LM) 目標的模型，更適合 Prompt Tuning。
- 在使用 Prompt Tuning 時，資料準備可以比 T5 的標準做法更簡單，因為軟提示本身已具備任務指導功能，所以可以省略輸入文本中的任務名稱前綴。