# 6.6.2 Review of Prompting Methods and PEFT

**回顧：讓大型語言模型 (LLM) 適應特定任務的方法**

過去幾次討論介紹了不同的方法，主要可以分為兩大類：

1. **提示工程 (Prompting / Prompt Engineering)**：
    - **核心機制**：**不更新**基礎 LLM 的任何模型參數。
    - **如何運作**：透過精心設計輸入的「提示」(Prompt) 來引導模型執行特定任務。所有執行任務所需的資訊（如任務描述、指令、範例）都必須包含在提示中。模型本身保持不變，只是根據提示內容觸發其內部的特定推理路徑。
    - **少樣本學習 (Few-shot Learning)**：提示工程的一種常見形式，在提示中提供少量（通常不超過 10 個）的輸入輸出範例，來引導模型理解任務。
    - **侷限性**：對於某些類型的任務，這種方法表現尚可。但對於許多需要更高性能或更複雜理解的任務，僅靠提示工程**往往無法達到所需的性能水平**。
    - **例子**：要求 LLM 總結一段文字，可以在提示中寫「請將以下文章總結成一段話：[文章內容]」。如果效果不好，可以加入範例：「範例輸入：[長文A] 範例輸出：[總結A]。現在請處理：[目標文章內容]」。整個過程中，LLM 的權重完全沒有改變。
	
2. **微調方法 (Tuning Methods)**：
    - **核心機制**：**會更新**模型的參數，讓模型學習適應特定任務。
    - **主要分類**：
        - **完整微調 (Full Fine-tuning - 隱含提及)**：更新模型中的**所有**參數。這種方法效果通常最好，但計算成本高、需要更多儲存空間（每個任務都要存一個完整模型）。
        - **參數高效微調 (Parameter-Efficient Fine-Tuning, PEFT)**：( **今天的重點** ) 只更新模型中**極小一部分**的參數，或者**額外增加一小組新的參數**進行訓練，而大部分原始模型的參數保持凍結。

**聚焦：參數高效微調 (PEFT)**

- **核心思想**：用最少的參數變動來適應新任務。
- **運作方式**：這些被更新或新增的**極少量**參數，能夠有效地捕捉到關於特定任務的關鍵知識。這些少量參數足以「引導」或「調節」(condition) 龐大的語言模型，使其在該特定任務上表現更好，具有更強的泛化能力。
- **"少量" 的概念**：這裡的「少量」是**數量級 (orders of magnitude)** 上的差異。
- **例子**：一個大型模型可能有數十億 (billions) 的參數。
    - _完整微調_ 可能需要更新全部幾十億個參數。
    - 而 _PEFT_ 方法（例如稍後會詳細討論的 Prompt Tuning），可能只需要更新**幾千個 (thousands)** 參數。這幾千個參數就能有效地引導整個數十億參數的模型，使其在特定任務上的表現**遠超**單純手動設計的提示 (manually created prompt)。

**總結**：相比於完全不改變模型的提示工程，以及改變所有參數的完整微調，PEFT 提供了一種更高效的折衷方案，透過調整極少量的參數，就能有效地讓大型語言模型適應特定任務，並達到比提示工程好得多的性能。