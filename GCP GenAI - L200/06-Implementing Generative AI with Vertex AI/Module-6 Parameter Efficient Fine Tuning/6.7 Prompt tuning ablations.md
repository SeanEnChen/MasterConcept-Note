# 6.6.7 Prompt tuning ablations

這部分主要在探討一些影響 Prompt Tuning 效果的細節因素，特別是與**基礎模型 (base model) 的大小**之間的關係。

**主要觀察點：**

1. **軟提示長度 (Soft Prompt Length) 的影響**：
    
    - 增加軟提示的長度（也就是使用更多的嵌入向量）通常會提升模型的性能，但**效果有上限**。
    - 研究發現，當軟提示長度達到大約 **20 個嵌入向量 (tokens)** 時，性能往往就**趨於飽和或穩定**（"even out"）。
    - 即使再增加長度到 100 或 150 個向量，性能可能也不會有顯著提升，呈現「**邊際效益遞減**」的現象。不過因為軟提示本身很小，增加長度對計算成本影響不大。
2. **基礎模型大小 vs. 軟提示長度**：
    
    - **關鍵發現**：隨著基礎模型的**規模變大**，軟提示的**長度變得越來越不重要**。
    - **舉例**：對於像 T5 XXL（110 億參數）這樣非常大的模型，即使只使用**長度為 1** 的軟提示（僅一個嵌入向量），其表現也**非常好**，只比使用更長提示（如 20 個向量）略差一點，但仍然能得到相當不錯的結果。
3. **基礎模型大小 vs. 初始化方法**：
    
    - 之前提到，如何初始化軟提示向量會影響性能。但這個影響**隨著基礎模型變大而減小**。
    - 對於非常大的模型，不同的初始化方法（例如隨機初始化 vs. 從詞彙表初始化）之間的**差異變得不太明顯**。
4. **基礎模型大小 vs. 預訓練/適應方式**：
    
    - 之前提到，經過 LM 適應（用預測下一個字詞的方式額外訓練）的模型表現更好。但這種**優勢的差距**也**隨著基礎模型變大而縮小**。
    - 同樣地，進行 LM 適應的具體步驟數等細節，在大模型上的重要性也相對降低。

**核心結論 (Bottom Line)：**

- **大型基礎模型是關鍵**：使用**更大、更強的基礎模型**本身，就能讓 Prompt Tuning 的效果更好。
- **細節調整的重要性降低**：隨著模型規模的增大，那些可以調整的小細節——比如軟提示的確切長度、用哪種初始化方法、或是對基礎模型做的少量適應調整——對於最終能否獲得好結果來說，其**重要性都相對下降了**。大型模型本身的強大能力成為了主導因素。

簡單來說，用 Prompt Tuning 時，選一個夠大的基礎模型，比在各種小技巧上斤斤計較可能更重要。

