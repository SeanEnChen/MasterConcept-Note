# 6.6.4 PEFT model-level approaches

這些方法的共通點是，在大型預訓練模型（例如 Transformer 架構的模型）的基礎上，只調整模型中一小部分的參數，就能讓模型適應特定的下游任務，同時保持大部分原始模型的參數不變（凍結）。這樣做可以大大減少訓練所需的計算資源、時間和儲存空間。

**1. Adapters (適配器)**

- **摘要與運作方式**：在預訓練模型（如 Transformer）的現有層之間，插入小型的、具有「瓶頸」結構（先降維再升維）的新神經網路層，稱為 Adapter 層。微調時，只訓練這些新加入的 Adapter 層的參數，原始模型的參數保持凍結。
- **具體範例**：
    - **任務**：讓通用的 BERT 模型（懂語言但不懂特定情感）學會判斷電影評論是正面還是負面。
	- **應用**：我們在原始模型的每一層 Transformer Block 內部（例如，在多頭注意力和前饋網路之後）都插入一個 Adapter 層。假設原始模型的內部維度是 768。這個 Adapter 層可能先將 768 維的向量降維到 64 維，做一些非線性轉換，再升維回 768 維。
	- **訓練過程**：原始模型的幾億、幾十億參數全部「凍結」不動。我們只用「電影評論情感標註數據」來訓練這些新加入的、總共可能只有幾十萬或幾百萬參數的 Adapter 層。
	- **結果**：這些 Adapter 學會了如何從原始模型的通用語言理解中，提取並強化與「情感判斷」相關的信號。例如，它學會了放大 "amazing storyline" (驚人故事情節) 的正面訊號，以及 "terrible acting" (糟糕演技) 的負面訊號。
- **適合情境**：
    - 當你需要在 **同一個基礎模型** 上訓練 **多個不同任務** 時。你可以為每個任務訓練一套輕量級的 Adapter 參數，部署時按需加載，非常節省儲存空間。
    - 注重 **參數效率** 和 **儲存空間**（Adapter 參數少）。
    - 可以接受對模型架構做少量修改。

**2. BitFit**

- **摘要與運作方式**：非常簡單的方法，它凍結模型中所有的主要權重矩陣，只更新（訓練）所有層的「偏置項 (bias terms)」。不改變模型架構。
- **具體範例**：
    - **任務**：微調一個大型語言模型，使其生成的文本風格從通用變為更像「專業客服」。
    - **應用**：找出模型中所有層的偏置項參數（就是線性轉換 `Wx + b` 中的那個 `b`）。
    - **訓練過程**：凍結所有巨大的權重矩陣 W。只用帶有「客服風格」標註的數據來更新這些相對數量很少的偏置項 `b`。
    - **結果**：透過調整偏置項，可能輕微改變了神經元的激活傾向，使模型在生成文本時更傾向於使用禮貌、溫和的詞彙和句式（例如，更常用禮貌用語、語氣更和緩），達到風格轉換的效果，儘管核心語言知識（W）未變。
- **適合情境**：
    - 計算資源或記憶體**極度有限**。
    - 追求**最簡單、改動最小**的微調方案。
    - 認為任務適應只需對模型輸出進行輕微的整體調整或風格偏移即可。
    - 作為快速實驗的**基線方法**。

**3. LoRA (Low-Rank Adaptation / 低秩適配)**

- **摘要與運作方式**：不直接修改大的權重矩陣 W，而是為其引入兩個小的、低秩的矩陣 A 和 B。微調時只訓練 A 和 B，原始的 W 保持凍結。權重的實際「變化量」由 A 和 B 的乘積 BA 來近似 (∆W ≈ BA)，最終使用 W' = W + BA。
- **具體範例**：
    - **任務**：讓通用的 Stable Diffusion 圖像生成模型學會生成特定「梵谷」畫風的圖片。
    - **應用**：我們選定模型中影響風格的關鍵權重矩陣（例如，在 U-Net 或 Cross-Attention 中的某些大型線性層）。假設一個關鍵矩陣 W 是 4096x4096。我們不直接改 W，而是為它加上兩個小矩陣 A (4096x8) 和 B (8x4096)。注意這裡的 rank 是 8，非常小。
    - **訓練過程**：凍結原始模型的 W。只用「梵谷」風格的圖片數據來訓練這些小的 A 和 B 矩陣（總共 4096x8 + 8x4096 = 65536 個參數，遠少於 W 的 1600 多萬參數）。
    - **結果**：訓練好的 A 和 B 矩陣相乘 (BA)，就代表了從「通用風格」到「梵谷風格」所需的「變化量」。在生成圖片時，模型實際使用的權重是 W + BA。這樣，模型就能根據你的文字提示（比如「一隻貓」），就能生成具有梵谷筆觸、色彩等風格特徵的圖像。
- **適合情境**：
    - 追求**較好微調性能**，同時**顯著減少訓練參數**數量。
    - 非常適合**風格遷移、領域適應**、注入特定知識等任務。
    - 方便**分享和切換**不同的微調效果（如分享 LoRA 文件）。
    - 在圖像生成、語言模型等領域廣泛應用且效果良好。

> [!note]
> 雖然兩個都是可以針對生成風格改變的例子，但是 BitFit 是修改 bias 的部分；而 LoRA 是針對模型的權重 W 去進行簡單的微調，是直接修改了核心的生成規則，是更深層更具體的修改，所以 LoRA 更能夠學習複雜的新模式。
> - **BitFit** 像是在調整一個系統的 **基礎設定或全局偏移**（只動 `b`），適用於較簡單、整體的風格微調。
> - **LoRA** 像是在 **修改系統處理資訊的核心演算法或規則**（間接動 `W`），能夠學習更複雜、更具體的風格模式和知識。

**4. Prompt Tuning (提示調整)**

- **摘要與運作方式**：完全不改變模型本身的任何參數。它在輸入端學習一組可訓練的連續向量（稱為「軟提示」），這些向量會被添加到實際輸入文本的嵌入表示之前，引導模型產生特定任務的輸出。
- **具體範例**：
    - **任務**：讓通用的 T5 問答模型能回答某公司內部的規章制度問題。
    - **應用**：我們定義一串（比如 20 個）可學習的「軟提示」向量，維度與模型的詞嵌入維度相同。
    - **訓練過程**：凍結整個語言模型。我們用「公司規章問題與答案」的數據對來訓練這 20 個提示向量。例如，輸入變成 `[軟提示向量序列] + [問題文本的嵌入向量]`，目標是輸出正確的答案文本。
    - **結果**：學好的軟提示像一個針對特定任務的「優化指令」，引導被凍結的 T5 模型在回答相關問題（如「年假規定」）時，能夠在其通用知識基礎上，結合提示給出的上下文線索，生成符合公司情況的答案。
- **適合情境**：
    - 當你 **完全不想修改或儲存** 任何模型本身的參數副本時。
    - 需要管理和快速切換 **極多任務**（每個任務只需存儲很小的提示向量）。
    - 對 **儲存效率** 要求最高。
    - 對模型改動最少，實現簡單。

**5. Ladder**

- **摘要與運作方式**：透過一個額外添加的、較小的「側邊網路」和特殊的「階梯連接」來影響主網路，實現微調。其最核心的特點是，在訓練過程中，**反向傳播（梯度計算和更新）只需要通過這個小的側邊網路**，無需通過巨大的主網路。
- **具體範例**：
    - **任務**：一個大型的電商推薦系統模型，需要**非常頻繁地**根據用戶最新的點擊、購買行為來更新推薦結果，但完整訓練一次模型非常耗時耗資源。
    - **應用**：在巨大的主推薦模型（可能包含用戶和物品的億級嵌入向量）旁邊，掛載一個相對小很多的 Ladder 側邊網路。
    - **訓練過程**：當有新的用戶行為數據進來時，數據會通過主網路和側邊網路（它們之間有交互）。計算損失後，**梯度只會回傳到側邊網路** 並更新其參數。主網路的參數可能凍結或用很低的頻率更新。
    - **結果**：這個側邊網路能快速學習到近期用戶興趣的變化或新商品的熱度趨勢，並透過 Ladder 連接即時地「微調」主網路的推薦輸出，使得推薦結果能跟上變化，而無需承擔反向傳播通過整個龐大主網路的巨大計算和內存開銷。
- **適合情境**：
    - **訓練時的計算成本和記憶體開銷**是主要瓶頸。
    - 模型**體積非常巨大**，且需要**頻繁地更新或適應**新數據。
    - 訓練/更新環境的**計算資源受限**。

**總結來說：**

- **Adapters** 和 **Ladder** 透過增加新的小模塊來實現微調。
- **BitFit** 和 **LoRA** 透過只更新模型現有參數中的一小部分（偏置項或權重的低秩近似）來實現微調。
- **Prompt Tuning** 則是在輸入層面進行操作，學習添加到輸入的提示向量。
- **Ladder** 在計算和記憶體效率上有獨特優勢，因為它避免了在主網路上進行反向傳播。
