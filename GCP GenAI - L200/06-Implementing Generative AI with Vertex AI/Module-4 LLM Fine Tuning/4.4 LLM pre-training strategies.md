# 6.4.4 LLM pre-training strategies

這段內容主要在講解大型語言模型（LLM）的 **預訓練（Pre-training）策略**，特別是 **自我監督預訓練（Self-supervised pre-training）** 以及其不同的組合與延伸方式。

**核心概念：自我監督預訓練（Self-supervised pre-training）**

1. **定義：** 這是一種利用 **大量未標註（unlabeled）** 的文本資料來訓練模型的方法。
2. **目的：** 讓模型學習到語言的通用、基礎的理解能力（例如：語法、語義、世界知識）。可以針對單一語言或多種語言。
3. **方法（舉例）：** 將未標註的句子轉換成類似有監督學習的格式。常見的技巧是「預測序列中的下一個詞元（token）」（Next Token Prediction），也就是給模型一句話的前面部分，讓它預測下一個字或詞是什麼。透過這個過程，模型就能學會詞語搭配、句子結構等語言規則。
4. **資料來源：** 通常使用 **龐大** 且 **通用（General）** 的語料庫（例如：來自網路的大量文本、書籍等）。

**預訓練策略的組合與延伸**

預訓練通常是模型訓練流程的第一步，但可以有多種組合和後續步驟：

1. **通用預訓練 + 特定領域預訓練（Domain-specific Pre-training）**
    - **目的：** 在模型具備通用語言能力後，進一步加強其在特定專業領域（如醫療、法律、金融）的知識和理解。
    - **方法一：依序進行（Sequential）**
        - 先在 **通用** 語料庫上完成預訓練。
        - 接著使用 **特定領域**（例如：醫學論文、法律文件、金融報告）的語料庫 **繼續訓練（continue training）** 模型。
    - **方法二：聯合進行（Joint）**
        - **混合（mixture）** 通用語料庫和特定領域語料庫，然後 **同時（jointly）** 使用這個混合語料庫進行預訓練。
        - **舉例：** BloombergGPT 模型就是一個例子。他們混合了通用的文本資料和大量的金融領域專屬資料，一起進行預訓練，目標是打造一個特別擅長金融領域任務的模型。
	
2. **預訓練 + 指令微調（Instruction Tuning）**
    - **目的：** 在模型完成預訓練（可能包含通用和/或特定領域訓練）後，讓模型學習如何更好地理解和遵循人類的指令（instructions）來完成特定任務。
    - **流程：** 這通常是在預訓練 **之後** 的一個 **微調（fine-tuning）** 階段。
    - **說明：** 文本中提到這是一個非常流行但有時被誤解的階段，需要先理解 T5 模型才能深入了解其原理（但這裡未詳述原理）。
    - **舉例：** Google 的 `text-bison@001` 模型 (Vertex AI)。它是一個大型語言模型 (PaLM 2 for Chat)，先在 **通用** 語料庫上進行了預訓練，**然後** 使用 Google 內部稱為 "Nimbus" 的 **指令微調** 語料庫進行了微調。這樣訓練出來的模型，既有廣泛的語言知識，又能很好地理解並執行用戶的指令（例如回答問題、寫摘要、翻譯等）。
	
3. **多任務預訓練（Multitask Pre-training）**
    - **目的：** 在預訓練階段就讓模型學習處理多種不同的任務。
    - **方法：** 在預訓練的資料混合物中，除了未標註資料，還加入一些 **有標註（labeled）** 的 **監督式學習資料集（supervised datasets）**。這些資料集可能包含不同任務的範例（例如：翻譯、摘要、問答等）。
    - **舉例：** mT5 和 ExT5 等模型就是採用了這種策略，將多個有標註的任務資料集加入預訓練階段。

**總結與常見流程**

- 預訓練策略有很多種組合方式，研究人員仍在不斷實驗。
- 一個 **經過驗證且標準（proven and standard）** 的流程是：
    1. 使用 **自我監督** 方法，在 **通用** 語料庫上進行預訓練。
    2. （可選）加入 **特定領域** 的語料庫進行預訓練（依序或聯合）。
    3. **接著** 進行 **指令微調（Instruction Tuning）**。
- 許多實際應用中的模型（例如 Vertex AI 中的模型）都遵循了類似 `通用預訓練 -> 指令微調` 的流程。