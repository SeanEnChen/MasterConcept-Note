# 6.4.3 How do you train a language model

**模型訓練方法：最大似然估計 (Maximum Likelihood Estimation, MLE)**

語言模型主要通過一種稱為最大似然估計的方法進行訓練，這與訓練許多其他類型的神經網路類似。

- **高層次解釋：** 最大似然估計的目標是找到一組模型參數，使得模型預測的資料分佈最接近真實的資料分佈。
- **應用於語言模型：** 在語言模型的案例中，我們假設訓練數據（大量的文本）是從某個真實的機率分佈中抽樣得到的。我們的模型（通常是 Transformer）會嘗試近似或估計這個真實的機率分佈。通過最大似然估計，我們試圖找到一組模型權重（例如 GPT-3 的 1750 億個參數），使得觀察到我們訓練數據的可能性最大化。

**自監督學習 (Self-Supervised Learning)**

訓練語言模型的一個關鍵優勢是我們不需要大量的標註數據。我們可以利用任意的文本語料庫。

- **數據準備：** 我們將文本數據進行一些處理，將一個句子轉換成多個樣本。每個樣本包含一個輸入序列（一段文本）和緊隨其後的一個詞語。
    - **例子：** 對於句子 "The cat sat on the mat."，我們可以創建以下訓練樣本：
        - 輸入序列："The"，目標詞："cat"
        - 輸入序列："The cat"，目標詞："sat"
        - 輸入序列："The cat sat"，目標詞："on"
        - 輸入序列："The cat sat on"，目標詞："the"
        - 輸入序列："The cat sat on the"，目標詞："mat"
- **自監督的本質：** 這種方法被稱為自監督學習，因為我們是從未標註的數據中自動創建標註的訓練數據。預訓練模型的基礎就是採用這種方法，將未標註的數據集轉換為監督學習所需的格式。

**損失函數：交叉熵 (Cross-Entropy)**

通過最大似然估計的數學推導，我們可以得到在預訓練模型中使用的標準損失函數：交叉熵（Cross-Entropy）或KL散度（Kullback-Leibler Divergence）。

- **損失計算：** 我們比較模型在學習的任何階段生成的機率分佈與我們的訓練數據（即觀察到的機率分佈）。在我們的例子中，觀察到的機率分佈是一個one-hot編碼的向量。
    - **One-hot 編碼舉例：** 假設我們的詞彙表包含32,000個詞語。對於一個輸入序列和一個目標詞，我們的標籤數據將是一個長度為32,000的向量，其中除了目標詞對應的位置為1，其餘位置都為0。
- **優化目標：** 我們的目標是最小化這個交叉熵損失，這意味著我們希望模型的預測機率分佈盡可能接近真實的（one-hot編碼的）目標分佈。這個優化過程通常使用標準的隨機梯度下降（Stochastic Gradient Descent, SGD）等優化算法。

**Teacher Forcing**

在訓練語言模型時，我們使用一種稱為 Teacher Forcing 的技術，這與模型在推理時的工作方式不同。

- **訓練過程：** 我們總是將完整的輸入序列推送給模型，而不是像推理時那樣逐個生成標記並將其反饋到輸入中。
- **並行計算：** 如影片中的圖表所示，解碼器接收到來自我們示例的所有輸入標記，並嘗試預測向右移動一位的最佳序列。這意味著，對於序列中的每一個標記，模型都會同時計算下一個詞的機率分佈。
    - **例子：** 對於輸入序列 "all you need"，模型在訓練時會並行預測 "you", "need", 和下一個詞的機率分佈。
- **Transformer的優勢：** Transformer架構能夠並行處理這些計算，這大大提高了訓練大型模型的效率。
- **與推理的區別：** 需要注意的是，Teacher Forcing 允許模型在訓練時看到正確的下一個標記，即使它之前的預測是錯誤的。這有助於模型更快地學習。而在推理時，模型是根據自己生成的上一個標記來預測下一個標記的。

總而言之，語言模型通過 Maximum Likelihood Estimation, MLE 在大量的文本數據上進行自監督學習。訓練的目標是最小化模型的預測與真實數據之間的交叉熵損失。在訓練過程中，Teacher Forcing 技術允許模型並行處理輸入序列，從而提高了訓練效率。