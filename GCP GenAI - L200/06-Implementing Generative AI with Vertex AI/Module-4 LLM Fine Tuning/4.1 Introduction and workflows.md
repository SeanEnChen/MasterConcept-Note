# 6.4.1 Introduction and workflows

**基礎概念回顧：**

- **複雜的預訓練過程：** 訓練一個大型語言模型或生成模型以最終處理特定任務可能是一個非常複雜的過程，涉及多個階段。具體流程的複雜程度取決於模型的類型和下游任務的類型。有些步驟可能是可選的。
- **術語的模糊性：** 在預訓練、微調等術語的使用上存在一些模糊性。不同的研究人員和論文可能會以不同的方式使用這些術語。
- **概念模型：** 為了本次課程的目的，將使用一個概念模型。假設訓練工作流中的任何步驟，只要生成一個可以執行多個任務並且可以進一步適應特定任務的預訓練語言模型，都將被稱為**預訓練**。
- **模型適應：** 任何將模型適應於特定任務的工作流、額外的調整或任何提示工程，都將被寬泛地稱為**適應 (Adapting)**。

**與預訓練語言模型互動的兩種主要方式：**

1. **上下文學習 (In-context Learning)：** 通過生成提示來引導模型完成特定任務。在這個過程中，模型的參數不會發生改變，而是直接使用預訓練好的模型。本次課程不會涵蓋提示工程，因為之前已經有過相關的課程。
2. **調整 (Tuning)：** 通過改變模型的部分或全部參數來適應特定任務，從而捕獲特定任務的語義。這個術語“調整”是為了與Vertex AI將使用的術語保持一致。
    - **完全微調 (Full Fine-tuning)：** 適應模型的所有參數。本次課程將簡要介紹。
    - **參數高效微調 (Parameter-Efficient Tuning)：** 適應模型參數的一個子集或一些新的模型參數。下一次課程將深入探討各種參數高效微調技術，包括Vertex AI中已實現的提示微調方法。

**蒸餾 (Distillation)：**

- **正交主題：** 蒸餾在概念上與預訓練和微調是正交的，因為它可以在這兩種情況下使用。
- **主要目標：** 創建一個更小的模型，該模型在特定任務或多個任務上表現良好，但在推理方面效率更高。Rajash將會更詳細地介紹蒸餾以及不同的蒸餾技術。

總而言之，本次課程旨在為理解後續關於參數高效微調的內容打下堅實的基礎，首先回顧了LLM的一些核心概念和訓練流程，並簡要介紹了完全微調和蒸餾的概念。