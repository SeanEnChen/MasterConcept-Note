# 6.4.7 Tuning a Pre-trained Language Model (PLM)

這段內容主要在講解如何將 **預訓練好的語言模型（Pre-trained Language Model, PLM）** 應用於 **下游特定任務（Downstream Tasks）** 的三種主要方法，並詳細介紹了其中的 **完全微調（Full Fine-tuning）**。以下為您整理摘要：

**將預訓練模型應用於下游任務的三種主要方法：**

1. **完全微調（Full Fine-tuning）：**
    - **作法：** 使用特定任務的 **有標註資料集（labeled dataset）** 來 **繼續訓練（continue training）** 整個預訓練模型。在這個過程中，模型 **所有（或大部分）的參數都會被更新**。有時甚至可能增加比原模型更多的參數（如下面 GPT-1 的例子）。
    - **概念：** 這是遷移學習（Transfer Learning）的一種形式，已經應用很久了。
	
2. **參數高效微調（Parameter-Efficient Fine-tuning, PEFT）：**
    - **作法：** 只訓練模型中 **一小部分** 的參數，而 **大部分預訓練模型的參數保持凍結（frozen）** 不變。目標是用很少的可訓練參數來捕捉特定任務的語義。
    - **變形：** 有些 PEFT 方法會稍微改變模型架構（例如，注入額外的小層），有些則完全不改變原始模型架構（例如，Prompt Tuning，在模型旁邊訓練額外參數）。
	
3. **提示工程（Prompting / Prompt Engineering）：**
    - **作法：** **完全不更新** 基礎模型的任何參數。透過設計 **特定的輸入文本提示（prompt）** 來引導（condition）或觸發（trigger）凍結的模型執行特定任務的能力。
    - **備註：** 這部分內容在此未深入探討。

**深入探討：完全微調（Full Fine-tuning）的兩種風格**

完全微調是將預訓練知識遷移到特定任務的常用手段，有不同的實現方式：

**風格一：添加特定任務頭（Task-Specific Head）- 以 GPT-1 為例**

- **背景：** OpenAI 在 2018 年發布的第一個 GPT 模型（GPT-1）的論文 ("Improving Language Understanding by Generative Pre-training") 就非常側重於這種微調方式。當時他們稱預訓練階段為「無監督預訓練」，而預訓練+微調的整個過程為「自我監督訓練」（注意：術語的意義隨時間有所演變）。
- **作法：**
    - 保留預訓練好的 Transformer 模型主體。
    - 在 Transformer 的輸出之上，**添加一個額外的小型神經網路層**（通常是一個**線性層/全連接層**），這個層被稱為「任務頭」。
    - 針對特定任務，只訓練（或主要訓練）這個新添加的任務頭，以及可能微調 Transformer 的部分參數。
- **例子（GPT-1 論文描述）：**
    - **分類任務：** 將文本輸入 Transformer，其輸出（公式中的 `H_lm`）再通過一個**新增的線性層**（參數矩陣 W_y）來預測任務的類別機率分佈。
    - **相似度/多選題任務：** 可能需要更複雜的輸入結構。例如，將多個句子（如前提和假設）分別通過 Transformer，可能每個都有獨立的線性頭，最後透過一個聯合的損失函數（Joint Loss Function）來計算整體損失並進行訓練。
- **核心：** 透過在預訓練模型之上 **添加額外的、針對任務的參數層** 來適應下游任務。

**風格二：統一為文本到文本框架（Text-to-Text Framework）- 以 T5 為例**

- **背景：** Google 在 2019 年底（文本提到 GPT-1 幾個月後）發布的 T5 模型論文 ("Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer") 提出了一種影響深遠的新範式。他們論文中的「遷移學習」主要指的就是微調。
- **核心思想：** 將**所有**自然語言處理（NLP）任務都 **統一轉換為「序列到序列」（Sequence-to-Sequence）** 的格式，即輸入是一段文本，輸出也是一段文本。
- **優點：**
    - **不需要修改模型架構。**
    - **不需要為不同任務添加不同的「任務頭」。** 同一個預訓練好的 T5 模型架構可以用於所有任務。
- **作法：** 透過**精心設計輸入和目標文本的格式**來適應不同任務。
    - **輸入格式化：** 通常在原始輸入前**加上一個「任務前綴」（Task Prefix）**，用來告知模型當前要執行什麼任務。
    - **目標格式化：** 將任務的輸出（如類別標籤）也轉換成文本格式。
- **例子：**
    - **CoLA 資料集（語法判斷 - 分類任務）：**
        - 原始輸入：句子 "John may build master of himself."，原始目標標籤：`1` (代表可接受)。
        - 轉換後 T5 輸入：`"cola sentence: John may build master of himself."`
        - 轉換後 T5 目標：`"acceptable"` (文本標籤)。
    - **MNLI 資料集（自然語言推論）：** 輸入會包含前提（premise）和假設（hypothesis），並加上如 `"mnli premise: ... hypothesis: ..."` 的前綴，目標是輸出 `"entailment"`, `"contradiction"` 或 `"neutral"` 的文本。
    - **SQuAD 資料集（問答）：** 輸入會包含上下文（context）和問題（question），並加上如 `"question: ... context: ..."` 的前綴，目標是輸出答案的文本區段。
- **影響：** T5 提出的這種統一 Text-to-Text 框架極大地簡化了模型在多任務上的應用，成為後續許多研究和應用的基礎。

**總結一下關鍵差異：**
- **GPT-1 風格：** 像是在基礎引擎上**加裝**不同的「硬體」外掛（任務頭）來處理不同任務。
- **T5 風格：** 像是用**同一套硬體**（模型架構不變），但透過下達不同的「軟體指令」（改變輸入輸出文字格式與任務前綴）來處理不同任務。