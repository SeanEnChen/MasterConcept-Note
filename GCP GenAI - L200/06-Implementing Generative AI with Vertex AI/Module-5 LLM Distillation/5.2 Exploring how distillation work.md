# 6.5.2 Exploring how distillation work

這段內容介紹了模型蒸餾的概念、運作方式、關鍵要素，以及在當前大型語言模型 (LLM) 時代面臨的新挑戰。模型蒸餾是一種 **模型壓縮** 技術，核心思想是訓練一個 **較小的「學生」(Student) 模型**，讓它去學習一個 **大型的、預訓練好的「老師」(Teacher) 模型** 的行為，從而將老師的「知識」轉移給學生。

1. **Distillation 如何運作：**
    
    - **知識來源：** 這裡的「知識」主要不是指直接複製權重，而是利用老師模型輸出的「軟標籤」(Soft Labels)，也就是預測的完整機率分佈。
        - **舉例 (LLM)：** 老師 LLM 在預測下一個詞時，不會只給出最可能的詞，而是給出詞彙表中所有可能詞彙的機率分佈（例如：70% 是 "the"，10% 是 "a"，5% 是 "cat"...）。
        - **舉例 (圖像分類)：** 老師模型看到一張貓的圖片，可能輸出 {貓: 0.9, 狗: 0.08, 車: 0.02} 這樣的機率分佈，而不僅僅是 "貓"。
    - **學習目標：** 學生模型在訓練時，其目標是 **模仿老師模型的輸出機率分佈**。這通過一個「蒸餾損失」(Distillation Loss) 函數來實現，該函數計算並最小化老師和學生輸出機率分佈之間的差異（例如使用 KL 散度）。
    - **聯合訓練：** 通常，Distillation Loss 會與一個標準的監督學習損失（例如，使用真實標籤計算的交叉熵損失 Cross-Entropy Loss）結合，共同用於訓練學生模型。
	
2. **關鍵概念：「暗知識」(Dark Knowledge)：**
    - 指的是老師模型賦予 **非正確** 類別的那些微小機率值中所包含的資訊。
    - **舉例：** 在上面的貓圖片例子中，老師給「狗」分配了 8% 的機率。這其實告訴學生：「雖然這張圖最像貓，但它和狗也有一些相似之處」。這種關於類別間相似性的細微資訊，有助於老師模型具有更好的泛化能力。
    - 通過讓學生模仿老師的完整軟標籤（而不只是硬標籤 "貓"），這種有價值的「暗知識」得以傳遞給學生，從而提升學生的泛化能力。
	
3. **技術細節：「溫度」(Temperature) 縮放：**
    - **目的：** 為了從老師的軟標籤中提取更多信息，特別是「暗知識」。
    - **方法：** 在計算 Softmax 函數將模型內部數值（logits）轉換為機率時，引入一個稱為「溫度」(T) 的超參數，通常 T > 1。公式大致為 `P = softmax(logits / T)`。
    - **效果：** 較高的溫度會使輸出的機率分佈變得更「平滑」，不同類別之間的機率差異會減小，分佈的熵 (entropy) 更高。
        - **舉例：** T=1 時可能是 {貓: 0.9, 狗: 0.08, 車: 0.02}，提高溫度 T 後可能變成 {貓: 0.7, 狗: 0.2, 車: 0.1}。錯誤類別的機率被放大了。
    - **好處：** 這種更「軟」的目標能為每個訓練樣本提供比硬標籤或低溫軟標籤更豐富的監督信號，減少訓練過程中梯度 (gradient) 的變異性，可能使學生模型用更少的數據就能達到不錯的效果。
	
4. **Distillation 在現代 LLM 中的新挑戰：**
    - Distillation 並非新概念。**舉例：** 之前的 BERT 時代就有成功的蒸餾模型，如 DistilBERT、TinyBERT 等，它們顯著減小了模型大小並加速了推斷。
    - **現在 (2025 年) 面臨的新問題：**
        - **模型平行化 (Model Parallelism)：** 現在的 LLM 非常巨大，通常需要將模型拆分到多個硬體設備（如 GPU）上運行。這使得蒸餾過程的實現更複雜，需要專門的代碼和策略。
        - **規模 (Scale)：** 模型規模的急劇增大，意味著執行傳統蒸餾流程（需要老師模型進行大量推斷）的計算成本可能過於高昂。
        - **任務性質的轉變 (Shift in Nature)：** 應用場景從過去以**分類**或**回歸**任務為主，轉變為現在的**生成 (Generation)** 任務。生成任務的開放性和序列性，使得蒸餾的目標和方法需要不同於分類任務的設計。例如，如何有效地蒸餾生成長文本的能力，是一個活躍的研究領域。

---

總結來說，模型 Distillation 是通過讓小模型學習大模型的輸出機率（包含暗知識）來實現模型壓縮的有效方法，溫度縮放是其中一個常用技巧。儘管已有成功先例，但面對當前（2025 年於台北觀察到的）LLM 的巨大規模、分佈式訓練以及生成式任務的特性，如何高效且有效地進行蒸餾，仍然是需要持續研究和創新的重要方向。