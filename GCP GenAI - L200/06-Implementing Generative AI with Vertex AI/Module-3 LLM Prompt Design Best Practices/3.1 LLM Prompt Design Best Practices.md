# 6.3.1 LLM Prompt Design Best Practices

**核心觀點：**

- **加速開發與普及：** LLM和生成式AI的主要優勢在於能夠更快地構建解決方案，並讓更多人參與到開發過程中。
- **快速驗證與迭代：** LLM使得在幾天內創建概念驗證 (POC) 成為可能，這在過去可能需要數月時間。更快的速度也意味著可以更快地根據客戶或用戶需求進行迭代和調整。
- **三個核心問題：** 團隊在使用LLM時通常會問三個問題：
    1. **能否實現 (Can we build this?)：** 我們是否可以使用現有的LLM來實現這個用例？
    2. **如何構建 (How do we build it?)：** 如何分解工作流程並實施想法？
    3. **如何改進 (How do we make it better?)：** 如何通過質量保證 (QA) 和不斷的開發改進來完善解決方案？
- **常見應用場景：** LLM的常見應用包括問答（基於知識庫或開放網路）、推薦（個性化或上下文相關）、翻譯（語言翻譯以及將自然語言轉換為配置或數據格式）。
- **提示工程的藝術與科學：** 提示工程既是一門科學，因為存在一些基本原則，也是一門藝術，因為沒有嚴格的規則，需要實踐者根據具體情況進行調整。

**提示工程的核心原則與技巧：**

1. **模型的核心是預測下一個文本：** 理解LLM的本質是預測序列中的下一個詞或token，這對於有效地提示模型至關重要。
2. **“Unfancy Prompt Design” (簡潔的提示設計)：** 一種有效的提示設計包含三個部分：
    - **任務描述/指令 (Task Description/Instruction/Preamble)：** 告訴模型要做什麼，例如“將英語翻譯成法語”。
    - **少量示例 (Few Examples/Few-Shot)：** 提供幾個輸入和期望輸出的示例，幫助模型理解任務的細微差別。建議使用稍微複雜的示例來教導模型更深層次的知識。
        - **例子：** 翻譯“海水”、“薄荷”和“長頸鹿”成法語。
    - **提示 (Prompt)：** 實際需要模型處理的輸入，例如“奶酪”翻譯成法語。
3. **Chain of Thought Prompting (思維鏈提示)：** 用於更複雜的任務，通過展示逐步的推理過程來引導模型。
    - **例子：** 給出一個關於經濟指標的問題，並逐步展示如何計算答案。雖然對於一些更先進的模型，這種方法可能不再必要，但在需要模型解釋其推理過程的場景中仍然很有用。
4. **五到七個示例原則：** 在初步驗證一個想法是否可行時，通常只需要五到七個帶有指令的示例。如果超過這個數量仍然無法獲得好的結果，那麼增加更多示例可能不會有幫助，反而可能導致過擬合。
5. **Prompting是“作弊條”而非“教科書”：** Prompting更像是利用模型已有的廣泛知識，而不是教導模型全新的概念。

**實際應用案例分析：**

- **Wordcraft：** 一個基於早期Lambda模型的交互式寫作應用程序。儘管提供了多種複雜功能，但用戶最常使用的是簡單的“生成文本”功能，這表明簡單可靠的功能往往最受歡迎。
- **Copy.ai：** 一個使用LLM撰寫LinkedIn帖子的工具。它沒有讓用戶輸入一個複雜的提示，而是將任務分解為更小的步驟：指定要創建的內容類型、強調的內容和語氣，然後基於用戶輸入和預定義的有效短語構建提示。它還允許用戶查看候選示例並進行微調，提供了更好的用戶控制和更可靠的結果。

**改進LLM應用性能的方法：**

- **將生成任務轉化為分類任務：** 有時可以提高任務的安全性和可靠性，並允許使用更先進的方法，如PETs。
    - **例子：** 不要讓模型直接推薦，而是讓模型從幾個選項中選擇最合適的推薦。
- **Parameter-Efficient Fine-Tuning (PEFT)：** 一種僅使用少量示例（約100個）就能顯著提高分類任務準確性的技術，使其接近最先進的水平。這對於內容審核、意圖識別和支持請求分類等任務非常有效。PETs通過一種稱為參數壓縮的技術，將示例以更有效的方式融入模型中。

**總結：**

有效的提示工程是利用LLM的關鍵。理解模型的工作原理，採用結構化的提示設計，並根據任務的複雜性選擇合適的技術（如 Prompting、Prompt Tuning 或 PEFT），可以幫助企業更快地構建出更可靠、更有效的生成式AI解決方案。同時，關注用戶工作流程並將複雜任務分解為更小的步驟，可以提升用戶體驗和應用程序的性能。