# 7.5 Vector search with RAG

**核心主題：利用向量搜尋技術處理大型語言模型 (LLM) 的「幻覺」問題，以及課程回顧。**

**大型語言模型 (LLM) 的幻覺問題**

- **現象**：LLM（如聊天機器人）有時會產生完全錯誤或捏造的回應（例如，推薦根本不存在的「黃莓」）。這稱為「建立基準問題」或「LLM 幻覺」。
- **原因**：
    1. **知識限制**：LLM 的知識僅限於其訓練數據，可能不知道特定領域知識、公司內部資訊或即時資訊。
    2. **依賴提示**：LLM 通常假設使用者提供的提示是正確的，且只理解提示中明確給出的資訊，無法主動詢問更多情境。
    3. **無法驗證**：LLM 內部無法真正核對資訊的正確性。
- **傳統解決方法的局限**：
    - **微調 (Fine-tuning)**：昂貴（需要大量資料與運算資源）。
    - **專人審查**：昂貴、耗時，且不一定能抓到所有錯誤。
    - **提示工程 (Prompt Engineering)**：有幫助，但仍受限於 LLM 已有的知識。

**解決方案：檢索增強生成 (Retrieval-Augmented Generation, RAG) + 向量搜尋**

- **核心概念**：在讓 LLM 生成回應**之前**，先使用「向量搜尋」從外部知識庫中**檢索 (Retrieve)** 相關的、即時的資訊，然後將這些資訊**增強 (Augment)** 到原始提示中，最後再讓 LLM **生成 (Generate)** 回應。
- **RAG 運作流程**：
    1. 收到使用者輸入的提示 (Query)。
    2. 使用此提示透過**向量搜尋**查詢一個相關的知識庫（例如：公司文件、研究論文、最新新聞等）。
    3. 擷取最相關的資訊片段。
    4. 將這些檢索到的資訊片段**附加**到原始提示後面，形成一個「增強提示」。
    5. 將這個包含額外即時情境資訊的「增強提示」傳送給 LLM。
    6. LLM 根據原始問題**以及**提供的額外資訊來生成更可靠、更基於事實的回應。
- **優點**：
    - 將 LLM 的回答建立在**事實基礎**上。
    - 結合了搜尋的**驗證能力**，確保資料的即時性與準確性。
    - 提高結果的**可靠度**與**可信度**。
    - 有助於減少幻覺風險，且避免了昂貴的重新訓練或微調。

**RAG 應用範例：查詢研究論文的聊天機器人**

- **情境**：使用者想詢問 Google 研究論文涵蓋的主題。
- **挑戰**：LLM 無法精確記住數百份文件的內容。
- **RAG 作法**：
    1. 使用者提問。
    2. RAG 系統使用**向量搜尋**在論文資料庫中找出與問題相關的論文片段。
    3. 系統將「原始問題」+「找到的論文片段」+「指示（例如：僅使用搜尋結果，勿自行捏造）」組合成增強提示。
    4. 將增強提示送給 LLM。
    5. LLM 閱讀提供的論文片段，並生成摘要式回應。
- **效果**：免去了讓 LLM 記憶所有內容的負擔，降低產生幻覺的風險。

**實作實驗室 (Lab) 預告：**

- **目標**：使用 Vector Search 和文字嵌入建立一個小型搜尋引擎。
- **任務**：能回答程式碼相關問題（例如「如何在 SQL 中重組資料列？」），透過搜尋 Stack Overflow 的問題庫來找到答案。
- **資料**：800 萬個 Stack Overflow 問題。
- **步驟**：1. 生成資料嵌入 -> 2. 建立並部署 Vector Search 索引 -> 3. 執行查詢。

**課程總結：**

- **嵌入 (Embeddings)**：為業務資料提供了新的表示標準，對新一代使用者體驗至關重要。
- **向量搜尋 (Vector Search)**：在管理和毫秒級搜尋數十億嵌入方面扮演關鍵角色。
- **Vertex AI Vector Search**：提供了可擴展、可靠、正式環境品質的向量搜尋技術（許多 Google 服務的基礎），且易於使用。
- **RAG 應用**：學習了如何使用 Vector Search 建構 RAG 系統，以有效解決 LLM 的幻覺問題。

希望學員能透過本課程獲得啟發，並利用 Google Cloud 資源持續學習。