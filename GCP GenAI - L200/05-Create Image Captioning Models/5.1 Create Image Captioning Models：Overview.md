# 5.1 Create Image Captioning Models：Overview

**核心技術：**

- **編碼器-解碼器 (Encoder-Decoder)：** 模型的基本架構，編碼器處理圖像，解碼器生成文字。
    - **編碼器 (Encoder)：** 使用經典的 InceptionResNetV2（或其他圖像骨幹網路）提取圖像特徵並創建特徵向量。
    - **解碼器 (Decoder)：** 接收編碼器的特徵向量，並逐字生成圖像的文字描述（標註）。
- **注意力機制 (Attention Mechanism)：** 解碼器在生成每個詞語時，會根據圖像特徵和已生成的詞語來決定應該關注圖像的哪些部分。影片中使用了 `tf.keras.layers.Attention`，也提到了可以使用更像 Transformer 的 `tf.keras.layers.MultiHeadAttention`。
- **Transformer 元素：** 解碼器的設計受到 Transformer 的啟發，但仍然使用了循環神經網路 (RNN)，具體來說是 GRU。


**解碼器架構細節：**

- **迭代操作：** 解碼器是一個迭代的過程，透過不斷地呼叫自身（自迴歸）來生成文本。
- **Embedding Layer：** 將輸入的詞語轉換為詞嵌入向量。
- **GRU Layer：** 一種循環神經網路，用於處理詞語序列，保留先前詞語的依賴關係。
- **Attension Layer：** 結合了文本（GRU 的輸出）和圖像（編碼器的輸出）的信息，計算注意力分數。
- **跳躍連接 (Skip Connection/Residual Connection)：** 將 GRU 的輸出直接加到注意力層的輸出（經過層歸一化），這有助於訓練更深的神經網路。

**程式碼重點：**

- 使用 Keras Applications 中的 `InceptionResNetV2` 作為編碼器。
- 解碼器包含詞嵌入層、GRU 層、注意力層、加法層和標準化層。

**推論階段 (Inference Phase)：** 如何為任意圖像生成標註：

1. **初始化 GRU 狀態和 `<start>` 標記：** 在推論開始時，需要顯式地初始化 GRU 的內部狀態，並將 `<start>` 標記作為解碼器的第一個輸入。
2. **將輸入圖像傳遞給編碼器：** 提取圖像的特徵向量。
3. **迭代生成標註：** 在一個迴圈中，不斷呼叫解碼器，輸入前一個生成的詞語（初始為 `<start>` 標記）、當前的 GRU 狀態和圖像特徵。解碼器會預測下一個詞語，並更新 GRU 狀態。這個過程會持續到生成 `<end>` 標記或達到最大標註長度。

**與大型語言模型的關聯：** 這種簡單圖像標註模型的迭代生成方式，與 Google Bard 等大型語言生成模型逐字預測的原理非常相似。