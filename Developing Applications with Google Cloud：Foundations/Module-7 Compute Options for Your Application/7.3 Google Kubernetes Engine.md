# 7.3 Google Kubernetes Engine

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741673684000d5fi57.png)

**Kubernetes 與 GKE 簡介: (如上圖)**
- **Kubernetes:** 領先的開源平台，用於部署、擴展和運營容器。起源於 Google，現為 Cloud Native Computing Foundation 的專案，擁有龐大活躍的社群。Kubernetes 提供框架，以彈性和規模化方式運行分散式容器化系統，管理諸多運營任務，如應用程式組件擴展、網路抽象、故障轉移協調、部署滾動更新、儲存協調以及密碼和配置管理。
- **Kubernetes 叢集架構:** 包含控制平面 (Control Plane) 和工作節點 (Worker Nodes)。節點是運行應用程式的機器 (虛擬或實體)。控制平面管理工作節點和叢集中的 Pod。Pod 是節點上共享網路和儲存資源的容器組。
- **Google Kubernetes Engine (GKE):** Google Cloud 上託管的 Kubernetes 服務，協助使用者在 Google Cloud 上部署、管理和擴展容器化應用程式的 Kubernetes 環境。GKE 是 Google Cloud 運算產品的一部分，方便使用者將 Kubernetes 工作負載引入雲端。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741673749000rbdf7i.png)

- **非託管叢集 (Unmanaged Cluster) vs. GKE（如上圖）:** 非託管叢集需要使用者自行管理大部分運營方面。GKE 自動處理大部分運營工作，簡化 Kubernetes 叢集的創建和管理。
- **GKE 的管理職責:** Google 管理控制平面、Pod 擴展、節點修補和升級，以及叢集的監控、可用性和可靠性。預設情況下，使用者管理底層節點和節點池，包括配置、維護和生命週期管理。使用者也負責選擇叢集的安全性和網路配置。這種管理級別是 GKE 的標準模式 (Standard Mode)。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/174167383100042smog.png)

- **GKE Autopilot（如上圖）:** 完全託管的 Kubernetes 體驗，Google 管理整個叢集基礎架構，包括控制平面、節點池和節點。Autopilot 有助於降低運營和維護成本，同時提高資源利用率。專注於工作負載，而非叢集基礎架構的管理。Autopilot 自動實施 GKE 強化指南以及安全和網路最佳實務，並阻止不太安全的做法。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/17416739210000y3fo2.png)

- **GKE Standard 模式 vs. Autopilot 模式（如上圖）:** GKE Standard 模式為使用者提供對叢集基礎架構的高級配置靈活性。GKE Autopilot 模式讓 Google 配置和管理整個叢集和底層基礎架構。可以根據所需的基礎架構控制程度，為不同的叢集使用不同的模式。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741674034000jkvrx7.png)

**GKE 的主要特性和優勢（如上圖）:**
- **全託管 (Fully Managed):** 無需配置底層資源。
- **容器優化作業系統 (Container-Optimized OS):** GKE 使用容器優化作業系統運行工作負載，Google 維護此作業系統，使其能夠快速擴展並佔用最少的資源。
- **簡化的叢集部署 (Simplified Cluster Deployment):** 指示 GKE 實例化 Kubernetes 叢集即可開始使用。
- **自動升級 (Auto-Upgrade):** 啟用後，確保叢集始終自動升級到 Kubernetes 的最新穩定版本。
- **自動修復 (Auto-Repair):** 自動修復不健康的節點。定期對叢集中的每個節點執行健康檢查。如果節點被判定為不健康並需要修復，GKE 將排空節點，允許工作負載正常退出，然後重新創建節點。
- **工作負載和叢集自動擴展 (Workload and Cluster Autoscaling):** GKE 和 Kubernetes 都支援叢集中工作負載的擴展。GKE 也支援叢集自身的擴展。自動擴展根據叢集內部容器的資源需求變化來新增或移除運算實例。
- **監控與日誌 (Monitoring and Logging):** GKE 使用 Cloud Monitoring 和 Cloud Logging 幫助使用者監控和理解應用程式的效能和行為。
- **與 Google Cloud 的無縫整合 (Seamless Integration with Google Cloud):** 與 Cloud Build、Artifact Registry、IAM、VPC 和 Google Cloud Console 等多個 Google Cloud 服務無縫整合，實現自動化部署、安全映像儲存、存取控制、網路功能和資源管理。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741674106000jz6tdz.png)

- **廣泛的應用程式運行時支援 (Broad Application Runtime Support):** GKE 支援任何可以封裝為 Docker 映像的應用程式運行時。
- **混合雲和多雲支援 (Hybrid and Multi-Cloud Support):** 可以在混合雲或多雲環境中的 Kubernetes 上運行容器映像，適用於部分應用程式在內部部署，部分在雲端的場景。
- **非 HTTP/HTTPS 網路協定支援 (Non-HTTP/HTTPS Network Protocol Support):** 支援運行使用 HTTP 和 HTTPS 以外網路協定的容器化應用程式。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741674186000yxqnoo.png)

- **簡化的基礎架構管理 (Simplified Infrastructure Management):** GKE 簡化了與配置和管理 Kubernetes 環境基礎架構相關的許多運營任務。當創建 Kubernetes 持久卷以提供有狀態應用程式的儲存時，GKE 預設自動配置 Google Cloud 持久磁碟。部署 Kubernetes 網路負載平衡器服務時，GKE 自動配置 Google Cloud 網路負載平衡器；配置 Kubernetes Ingress 資源時，則配置 Google Cloud HTTP 和 HTTP(S) 負載平衡。
- **Google Cloud Observability 支援:** GKE 支援 Google Cloud Observability，提供與故障排除以及應用程式和服務監控工具的整合。
- **簡化的叢集部署和擴展 (Simplified Cluster Deployment and Scaling):** 描述希望在應用程式所需的所有容器中提供的運算、記憶體、網路和儲存資源，GKE 將自動配置和管理底層 Google Cloud 資源。可以部署固定大小的叢集，或配置叢集自動擴展。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741674243000w3xfpd.png)
![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/17416742680009dhcac.png)

**GKE 上的應用程式部署與管理:（如上圖）**
- 使用與其他 Kubernetes 環境相同的方式在 GKE 上部署和管理容器化應用程式。
- 使用 `kubectl` 命令執行大部分運營任務。
- 最佳實務是使用 YAML Manifest 檔案定義配置，定義應用程式組件容器的屬性、網路服務、安全策略和其他 Kubernetes 物件。
- 使用 Deployments 部署應用程式，Kubernetes 持續確保 Pod 或 Pod 集的指定副本數量正在運行，適用於無狀態組件。StatefulSets 適用於需要持久儲存的應用程式。
- 可以使用 YAML Manifest 檔案定義各種其他資源類型。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1741674344000m97kb4.png)

- 在持續整合和交付 (CI/CD) 管道中，可以為每次程式碼提交生成新的 Docker 映像。CI/CD 管道可以自動將映像部署到開發、測試和生產環境。Cloud Build、Artifact Registry、Cloud Deploy 和 GKE 可用於創建強大的 CI/CD 系統。

---

- **Introduction to Kubernetes and GKE:**
    
    - **Kubernetes:** A leading open-source platform for deploying, scaling, and operating containers. Originating from Google and now a Cloud Native Computing Foundation project, Kubernetes offers a framework for running distributed containerized systems resiliently and at scale. It manages operational tasks like application component scaling, network abstraction, failover orchestration, deployment rollouts, storage orchestration, and secret/configuration management.
    - **Kubernetes Cluster Architecture:** Comprises a Control Plane and Worker Nodes. Nodes are machines (virtual or physical) running applications. The Control Plane manages worker nodes and Pods within the cluster. Pods are groups of containers sharing network and storage resources on a node.
    - **Google Kubernetes Engine (GKE):** A managed Kubernetes service on Google Cloud, facilitating the deployment, management, and scaling of Kubernetes environments for containerized applications on Google Cloud. GKE is part of Google Cloud's compute offerings, aiding users in bringing Kubernetes workloads to the cloud.
- **GKE Management Modes:**
    
    - **Unmanaged Cluster vs. GKE:** Unmanaged clusters require users to manage most operational aspects. GKE automates much of this, simplifying Kubernetes cluster creation and management.
    - **GKE Management Responsibilities:** Google manages the Control Plane, Pod scaling, node patching and upgrades, and cluster monitoring, availability, and reliability. By default, users manage underlying nodes and node pools (provisioning, maintenance, lifecycle). Users also select cluster security and networking configurations. This management level is GKE Standard mode.
    - **GKE Autopilot Mode:** A fully managed Kubernetes experience where Google manages the entire cluster infrastructure – control plane, node pools, and nodes. Autopilot reduces operational and maintenance costs while improving resource utilization, allowing focus on workloads instead of cluster infrastructure management. Autopilot automatically implements GKE hardening guidelines and security/networking best practices, blocking less secure practices.
    - **GKE Standard vs. Autopilot:** GKE Standard offers advanced configuration flexibility. GKE Autopilot lets Google manage the entire cluster and infrastructure. Different modes can be used for different clusters based on required infrastructure control levels.
- **Key Features and Benefits of GKE:**
    
    - **Fully Managed:** No need to provision underlying resources.
    - **Container-Optimized OS:** GKE uses a container-optimized OS, maintained by Google for rapid scaling and minimal resource footprint.
    - **Simplified Cluster Deployment:** Users simply direct GKE to instantiate a Kubernetes cluster.
    - **Auto-Upgrade:** Ensures clusters are always automatically upgraded to the latest stable Kubernetes version when enabled.
    - **Auto-Repair:** Automatically repairs unhealthy nodes by periodically health-checking each node, draining workloads from unhealthy nodes, and recreating them.
    - **Workload and Cluster Autoscaling:** Both GKE and Kubernetes support workload scaling within clusters. GKE also supports cluster autoscaling, adding or removing compute instances based on container resource needs.
    - **Monitoring and Logging:** GKE uses Cloud Monitoring and Cloud Logging to help users monitor and understand application performance and behavior.
    - **Seamless Integration with Google Cloud:** Integrates with Cloud Build, Artifact Registry, IAM, VPC, Google Cloud Console, etc., for automated deployment, secure image storage, access control, networking features, and resource management.
    - **Broad Application Runtime Support:** GKE supports any application runtime packaged as a Docker image.
    - **Hybrid and Multi-Cloud Support:** Container images can run on Kubernetes in hybrid or multi-cloud environments, beneficial for applications partly on-premises and partly in the cloud.
    - **Non-HTTP/HTTPS Network Protocol Support:** Supports containerized applications using network protocols beyond HTTP/HTTPS.
    - **Simplified Infrastructure Management:** GKE simplifies operational tasks of provisioning and managing Kubernetes infrastructure. Google Cloud Persistent Disks, Network Load Balancers, and HTTP(S) Load Balancing are auto-provisioned for Kubernetes Persistent Volumes, Network LoadBalancer services, and Ingress resources respectively.
    - **Google Cloud Observability Support:** GKE supports Google Cloud Observability, integrating with troubleshooting and monitoring tools.
    - **Simplified Cluster Deployment and Scaling:** Users describe desired compute, memory, network, and storage resources, and GKE auto-provisions and manages underlying Google Cloud resources. Clusters can be fixed-size or autoscaling.
- **Application Deployment and Management on GKE:**
    
    - Containerized applications are deployed and managed on GKE like any other Kubernetes environment.
    - `kubectl` command used for most operational tasks.
    - Best practice is to use YAML manifest files to define configurations, including container properties, network services, security policies, and other Kubernetes objects.
    - Deployments manage stateless components by ensuring specified replica counts of Pods are running. StatefulSets manage stateful applications requiring persistent storage.
    - YAML manifests define various resource types.
    - In CI/CD pipelines, new Docker images can be generated per code commit, and the pipeline can automate image deployment to development, test, and production using Cloud Build, Artifact Registry, Cloud Deploy, and GKE.