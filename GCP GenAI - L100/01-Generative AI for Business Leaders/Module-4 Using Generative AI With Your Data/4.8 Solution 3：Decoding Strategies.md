# 3.8 Solution 3：Decoding Strategies

**一、Introduction to Decoding Strategies**

大型語言模型擁有大量的參數，並在大量的文本數據上進行預訓練，這有助於當今使用的模型的成功和品質。選擇輸出 Token 的方式對於產生更好的回應也非常重要。有多種選擇輸出 Token 的方法，這些方法稱為 **decoding strategies**。理解 **decoding strategies** 以及 LLM 如何使用它們，將使您能夠更有效率地設計更好的提示。先前，您已經了解了一些常見的 **decoding strategies**，現在您將探索一些可以調整的參數，以幫助您從大型語言模型獲得更好的回應。

**二、Key Parameter**

讓我們從三個關鍵參數開始：Temperature (溫度)、Top K 和 Top P。所有三個參數都可以在 Vertex AI 控制台和 API 中使用。除了精心設計您的提示和編寫文本外，您還可以調整這三個參數，以期從模型中獲得更好的回應。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742197368000afw004.png)

**三、Key Parameter: Temperature**

這些參數中的第一個稱為溫度 (temperature)。溫度是一個可用於調整隨機程度的數字。**較低的溫度意味著較少的隨機性**，而**較高的溫度意味著更多的隨機性**。如果您將溫度設定為零，這是確定性的，並且等同於貪婪解碼 (greedy decoding)，它只選擇機率最高的詞元。

較低的溫度通常更適合問答或摘要等任務，在這些任務中，您需要更正確或更明確的答案。在非常低的溫度下，您可能會發現模型開始重複自身。

另一方面，較高的溫度意味著更多的隨機性，這通常會產生更不尋常或令人驚訝的回應。這可以被認為是一種更具創造性的方法，但在非常高的溫度下，您可能會注意到模型開始偏離主題或變得非常荒謬。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742197501000h4cai6.png)

這是一個更直觀的溫度範例。輸入的短語是「what did the mouse eat?」(老鼠吃了什麼？)。當然，正如您可能預期的那樣，機率最高的詞是「cheese」(起司)。但「cookie」(餅乾) 的可能性也很高，然後是與起司相關的答案「fondue」(起司火鍋)。如果您將溫度一直降低到零，它會消除所有其他可能性，「cheese」是唯一可能的詞。隨著您提高溫度，它會使這種機率分佈變得平坦，這使得所有其他詞的可能性都稍微增加，這意味著您現在可能會得到更具創造性的答案，因為您可以選擇像「banana」(香蕉)、「baguette」(法國長棍麵包) 或「cake」(蛋糕) 這樣的詞。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/174219782300082gkzq.png)

讓我們稍微解釋一下數學原理。這與所有神經網路的概念相同。這裡有一些 logits，它們的總和不等於 100。這些 logits 通常會通過一個 softmax 層進行歸一化。因此，使用溫度時發生的情況是，每個 logit 本質上都除以了溫度。

**四、Key Parameter: Top K**

除了調整溫度之外，一種常用的技術是 Top K，您從前 K 個機率最高的詞元的候選列表中進行抽樣。這種方法允許其他高分詞元也有機會被選中。這種抽樣方法引入的隨機性在許多情況下有助於提高生成品質。需要注意的是，將 top-k 參數設定為 1 將導致貪婪解碼。當有多個機率較高的詞時，Top K 可以很好地工作，但是，Top-K 抽樣的一個問題是，它不會動態調整從下一個詞的機率分佈中過濾掉的詞的數量。因此，如果您有一個分佈，其中一個詞的可能性非常高，而其他所有詞的可能性都很低，那麼這可能會導致一些不合適的回應。因此，在將樣本池限制為固定大小 K 時要小心，因為對於陡峭的分佈，這可能會導致模型產生荒謬的輸出。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/17421979240009ffm5p.png)

**五、Key Parameter: Top P**

選擇最佳 top-k 值的困難導致了另一種流行的解碼策略，該策略可以動態設定詞元候選列表的大小。使用 Top P，您可以從累積機率大於或等於 P 的最小可能詞集中進行選擇。這樣，集合中的詞數可以根據下一個詞的機率分佈動態增加和減少。P 在 K 之後起作用，這意味著 Top P 將動態設定由 Top K 建立的候選詞列表的大小。一般來說，您可能不會經常調整 top p 和 top k。但是這些參數在 Vertex AI 中是公開的，因此了解它們對您是有益的。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742197935000q5scwx.png)
