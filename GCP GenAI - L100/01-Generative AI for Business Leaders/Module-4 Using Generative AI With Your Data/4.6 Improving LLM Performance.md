# 4.6 Improving LLM Performance

**一、Methods for Making LLMs More Reliable**

有各種方法可以使 LLM 更可靠，有些方法易於學習和應用，而另一些方法則非常複雜、耗時且昂貴。

**二、Prompt Design**

改進 LLM 效能的首要嘗試始終應該是 prompt design，即創建一個清楚描述模型應做什麼的提示 (creating a prompt that clearly describes what the model should do)。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742195043000qqlnej.png)

**三、Decoding Strategies and Prompt Tuning**

其次，您應該探索 decoding strategies 或提示調整 prompt tuning，方法是更改溫度 temperature 等參數，以定義模型應該有多有創意或多麼基於事實。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742195073000fkcwna.png)

**四、Grounding and Retrieval Augmented Generation (RAG)**

接下來是 Grounding 和 Retrieval Augmented Generation, RAG (檢索增強生成)。
- Grounding 是指不僅使用 LLM 訓練的數據，還使用 LLM 可以存取的外部資訊來源（例如資料庫）來回答問題，並在答案中引用該數據。
- 檢索增強生成 (RAG) 是一種常用於實現基礎的模式。它包含 3 個步驟：
	1. 首先，使用者向 LLM 提問
	2. 其次，LLM 不是直接回答問題，而是搜尋資料庫或第三方系統以收集資訊
	3. 第三，LLM 使用從資料庫或第三方系統檢索到的資訊摘要來回答使用者
- Vertex AI Agent Builder 是一個 RAG 系統的範例，您可以使用它創建開箱即用的搜尋和對話應用程式，這些應用程式可以根據您的企業數據來回答問題。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/17421952140009yo0ok.png)

**五、Task-Specific Tuning and Parameter-Efficient Fine Tuning methods, PEFT**

任務特定的調整 (task-specific tuning) 可以使 LLM 更可靠。

廣義地說，調整 (tuning) 是指透過在新數據上訓練模型，使模型適應新領域或一組自定義使用案例的過程。最明顯的方法可能是微調 (fine tuning)，即引入您自己的數據集，並透過調整 LLM 中的每個向量權重來重新訓練模型。這需要大量的訓練工作和託管您自己的微調模型。您將從預訓練中學習到的權重開始，並使用這些權重作為起點，您需要在您的特定數據集上訓練模型。

那麼，有沒有更有效率的模型調整方法呢？有，那就是參數高效微調方法 (Parameter-Efficient Fine Tuning methods, PEFT)。這些方法可用於在您自己的自定義數據上調整 LLM，而無需複製模型。在 LLM 中，您有一個包含神經元、輸入和權重的輸入層。這些輸入通過多個隱藏層傳遞，以在輸出層中生成輸出。使用 PEFT 方法，您不會修改基礎模型或權重，而是插入一個新的隱藏層來修改最終輸出。

Vertex AI 提供了一種參數高效調整服務 (Parameter Efficient Tuning service)，該服務能夠針對特定任務調整模型，而無需重建整個基礎模型，並允許客戶引入自己的數據。輸入數據是客戶數據，在整個過程中都經過安全儲存 - 靜態和傳輸中都經過加密。
- 客戶可以使用客戶管理的加密金鑰來控制儲存的適配器的加密，並且可以隨時刪除適配器權重。
- 調整後的權重也經過安全儲存，客戶將擁有使用任何調整後模型的唯一存取權。
- 並且，未經客戶許可，用於訓練適配器模型的客戶數據（例如提示和輸入數據）將不會被記錄或用於改進基礎模型。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/174219538600012zyhs.png)
![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742195481000zbmikc.png)

**六、Complexity and Cost Comparison of Different Methods**

您可以想像，完整地微調模型在成本、時間和資源等多個方面都非常昂貴，這使得它對於許多使用案例來說都是不切實際的解決方案。

將人工時與計算時進行比較並不完全等價，但作為一個總體框架，您可以將這些方法在改進 LLM 時的複雜性視為遞增的。
- 透過 Prompt Design，您可以編寫您想要執行的任務的描述，這不需要更新基礎模型或權重。您可以在此測試您的提示策略，例如 Few Shot、Chain of Thought 或 ReAct，您將很快了解這些策略。透過提示調整，您可以透過修改 temperature、top-k 和 top-p 等參數來調整模型的輸出以適應特定任務，模型和權重不會更改。
- 檢索增強生成不會更改基礎模型，但會執行搜尋以從數據儲存區檢索一些資訊，供 LLM 用於回應摘要。
- Parameter-Efficient Fine Tuning methods 是一種軟調整方法，當企業擁有數千個回應範例並希望調整模型以特定方式回應時可以使用。例如，如果您想針對特定行業訓練模型，或者想從某些內部來源提取數據，則可以使用此方法。此方法會在基礎模型中添加一個新的權重層，您負責更新該權重層。這可能需要數百美元。
- Fine Tuning 將創建一個新版本的基礎模型，您需要收集一個大型的標記訓練數據集，並透過調整 LLM 中的每個權重來重新訓練模型。Fine Tuning 需要更新所有基礎模型權重，而且成本要高得多，高達數百萬美元。不建議將其用於大多數使用案例。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/174219553000085z01r.png)
