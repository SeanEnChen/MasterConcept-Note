# 4.5 Limitations of LLMs

**一、Limitations of LLMs (LLM 的局限性)**

重要的是要理解，LLM 確實存在一些可能影響看似合理的對話產生的局限性。LLM 的設計目的是預測序列中的下一個詞 (LLMs are designed to predict the next word in a sequence)。它們在這樣做時不一定需要「真實」 (They are not required to be “truthful” when doing so)。LLM 可能會產生看似合理但與主題無關或事實上不正確的陳述 (LLMs can generate plausible-looking statements that are irrelevant or factually incorrect)。

**二、Examples of LLM Hallucinations (LLM 產生幻覺的例子)**

如果您要求 LLM 推薦晚餐地點，您可能會發現它推薦了一家位於不同城市或根本不存在的餐廳 (If you asked an LLM for a recommendation for where to eat dinner, you might find that it recommended a restaurant that exists in a different city, or never existed at all)。

**三、Misalignment Between Training and Practical Use (LLM 訓練與實際應用之間的落差)**

LLM 的訓練方式與實際應用方式之間存在不一致 (There is misalignment between how LLMs are trained and how they might be used in practice)。

**四、Dealing with Hallucinations is a Fundamental Challenge (處理幻覺是 LLM 的基本挑戰)**

處理幻覺是 LLM 的一個基本挑戰 (Dealing with hallucinations is a fundamental challenge of LLMs)，也是一個持續研究的領域 (and an ongoing area of research)。當您考慮如何在實踐中使用 LLM 時，這一點很重要 (Which is important to keep in mind, when you think about how you might use LLMs in practice)。

**五、Practical Limitations of a Single Model (單一模型的實際限制)**

我們可以用一個模型做這麼多事情是很棒的 (It’s great that we can do so much with a single model)。然而，一個可以做所有事情的模型存在實際的限制 (However a model that can do everything has practical limitations)。

![gh](https://raw.githubusercontent.com/SeanChenR/img_gif/main/myimage/1742194879000hgxvrg.png)
