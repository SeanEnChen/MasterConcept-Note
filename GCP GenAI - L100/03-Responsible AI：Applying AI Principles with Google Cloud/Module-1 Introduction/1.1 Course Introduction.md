# 1.1 Course Introduction

**一、Course Introduction: Applying AI Principles with Google Cloud**

本課程旨在探討如何在 Google Cloud 上應用 AI 原則，著重於負責任的 AI 的實踐。

**二、Prevalence and Importance of AI**

許多人每天都在與人工智慧 (AI) 互動，從交通和天氣預報到電視節目推薦。隨著 AI，尤其是生成式 AI (generative AI) 的普及，許多非 AI 技術可能顯得不足。這種強大且影響深遠的技術引發了關於其開發和使用的重要問題。

**三、Evolution and Rapid Development of AI**

過去，AI 並非普通人可以輕易接觸。大多數接受過 AI 訓練並有能力開發 AI 的人都是數量稀少且成本高昂的專業工程師。但現在，進入門檻正在降低，讓更多人能夠開發 AI，即使是那些沒有 AI 專業知識的人也能做到。AI 系統現在能夠以十年前難以想像的方式觀察、理解和與世界互動，並且這些系統正以驚人的速度發展。根據史丹佛大學 2019 年的 AI 指數報告，在 2012 年之前，AI 的發展與摩爾定律密切相關，運算能力每兩年翻一番。報告指出，自 2012 年以來，運算能力大約每 3.5 個月翻一番。在此期間，視覺 AI (Vision AI) 技術變得更加準確和強大。例如，ImageNet（一個圖像分類數據集）的錯誤率顯著下降。2011 年的錯誤率為 26%，而到 2020 年，這個數字降至 2%。作為參考，人類執行相同任務的錯誤率為 5%。

**四、Definition and Core Concepts of Responsible AI**

儘管取得了顯著進展，AI 並非完美無缺。開發負責任的 AI 需要理解可能的問題、限制或意外後果。技術反映社會，因此，如果沒有良好的實踐，AI 可能會複製並放大現有的偏見。然而，「負責任的 AI」(responsible AI) 沒有普遍的定義，也沒有簡單的檢查清單或公式來定義如何實施負責任的 AI 實踐。相反，各組織正在制定自己的 AI 原則 (AI principles)，以反映其使命和價值觀。雖然這些原則因組織而異，但它們通常包含透明度 (transparency)、公平性 (fairness)、責任 (accountability) 和隱私 (privacy) 等共同主題。

**五、Google's Commitment to Responsible AI**

在 Google，我們對負責任的 AI 的方法植根於致力於開發為所有人打造、負責任、安全、尊重隱私並以卓越科學為驅動的 AI。我們已經開發了自己的 AI 原則、實踐、治理流程和工具，這些共同體現了我們的價值觀並指導我們對負責任的 AI 的方法。我們已將責任設計 (responsibility by design) 融入我們的產品，更重要的是，融入我們的組織。像許多公司一樣，我們使用我們的 AI 原則作為指導負責任決策的框架。我們將在本課程的後續部分詳細探討我們是如何做到這一點的。重要的是在這裡強調，我們並不聲稱擁有所有的答案。我們知道這項工作永無止境，我們希望分享我們正在學習的內容，以進行協作並幫助其他人踏上他們自己的旅程。

**六、Importance of Human Decision-Making in AI Development**

我們所有人在如何應用負責任的 AI 方面都扮演著重要的角色。無論您參與 AI 流程的哪個階段，從設計到部署或應用，您所做的決定都會產生影響。重要的是，您也應該擁有一個明確且可重複的負責任地使用 AI 的流程。Google 不僅致力於開發具有社會價值的先進技術，還致力於透過與更廣泛的社群分享我們的見解和經驗教訓來推廣負責任的實踐。本課程正是這些努力的一部分。

**七、Course Goals**

本課程的目標是提供一個了解 Google，更具體地說是 Google Cloud 在負責任地開發和使用 AI 方面的歷程的窗口。我們希望您能夠利用我們分享的資訊和資源來幫助塑造您組織自身的負責任的 AI 策略。但在我們深入了解之前，讓我們澄清一下我們談論 AI 時的含義。通常，人們想知道人工智慧、機器學習和深度學習之間的區別。然而，AI 沒有普遍認可的定義。關鍵的是，圍繞如何定義 AI 缺乏共識並沒有阻止技術進步，這突顯了需要就如何負責任地創建和使用這些系統進行持續對話。在 Google，我們說我們的 AI 原則適用於作為涵蓋所有類型技術的保護傘的先進技術開發。陷入語義上的爭論可能會分散人們對核心目標的注意力：負責任地開發技術。因此，我們不會深入探討這些技術的定義，而是將重點放在人類決策在技術開發中的重要性。人們普遍認為人工智慧的核心決策者是機器。但實際上，是人類設計和建造這些機器並決定如何使用它們。人類參與 AI 開發的每個環節。他們收集或創建模型訓練所需的數據。他們控制 AI 的部署以及如何在特定環境中應用它。本質上，人類的決策貫穿於我們的技術產品。每次人們做出決定時，他們實際上都是根據自己的價值觀做出選擇。無論是決定使用生成式 AI 來解決問題，而不是其他方法，還是在機器學習生命週期的任何環節，他們都會引入自己的一套價值觀。這意味著每個決策點都需要考慮和評估，以確保從概念到部署和維護的整個過程中的選擇都是負責任的。