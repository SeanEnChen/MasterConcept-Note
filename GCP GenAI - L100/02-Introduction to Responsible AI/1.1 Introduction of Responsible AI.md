# 1.1 Introduction of Responsible AI

**一、Introduction to Responsible AI**

AI 正被廣泛討論，但負責任地使用 AI 意味著什麼？負責任的 AI 的定義並非普遍，也沒有簡單的檢查清單或公式來定義如何實施負責任的 AI 實踐。相反，組織正在制定自己的 AI 原則 (AI principles)，以反映其使命和價值觀。儘管這些原則因組織而異，但它們通常包含透明度 (transparency)、公平性 (fairness)、責任 (accountability) 和隱私 (privacy) 等共同主題。Google 對負責任的 AI 的方法植根於致力於開發為所有人而設計、負責任、安全、尊重隱私並以卓越科學為驅動的 AI。責任設計 (responsibility by design) 已融入 Google 的產品和組織中。AI 原則作為一個框架，指導著從設計到部署或應用等 AI 流程各個階段的負責任決策。

**二、The Role of Humans in AI Development**

人們普遍認為人工智慧的核心決策者是機器，但實際上，是人類設計和建造這些機器並決定如何使用它們。人類參與 AI 開發的每個環節，包括收集或創建模型訓練所需的數據、控制 AI 的部署以及如何在特定環境中應用它。人類的決策貫穿於技術產品，每次決策都基於個人的價值觀。無論是決定使用生成式 AI (generative AI) 來解決問題，還是機器學習生命週期中的任何環節，個人都會引入自己的價值觀。因此，每個決策點都需要仔細考慮和評估，以確保從概念到部署和維護的整個過程中的選擇都是負責任的。

**三、Importance of Responsible AI**

負責任的 AI 不僅僅關注那些明顯具有爭議的用例。即使是看似無害或出於善意的 AI 用例，如果沒有負責任的 AI 實踐，仍然可能導致道德問題或意外後果，或者無法發揮其應有的益處。道德和責任不僅僅是正確的事情，它們還可以引導 AI 設計更有利於人們的生活。Google 已經了解到，將責任融入任何 AI 部署都能產生更好的模型並建立與客戶及其客戶的信任。信任一旦被打破，AI 部署可能會停滯不前、失敗，甚至對相關人員造成傷害。Google 認為負責任的 AI 等於成功的 AI。他們透過一系列的評估和審查來制定與 AI 相關的產品和業務決策，以確保跨產品領域和地區的方法的嚴謹性和一致性。這些評估和審查始於確保任何專案都符合他們的 AI 原則。

**四、Google's Seven AI Principles**

儘管 AI 原則有助於團隊達成共同承諾，但並非所有人都會同意關於如何負責任地設計產品的每個決定。這就是為什麼開發人們可以信任的健全流程非常重要。即使他們不同意最終的決定，他們也會信任做出決定的過程。Google 於 2018 年 6 月宣布了七項 AI 原則來指導他們的工作。這些是積極管理其研究和產品開發並影響其業務決策的具體標準。這七項原則是：

1. AI should be socially beneficial (AI 應具有社會效益)。任何專案都應考慮廣泛的社會和經濟因素，只有當我們相信整體可能的益處顯著超過可預見的風險和弊端時才會進行。
2. AI should avoid creating or reinforcing unfair bias (AI 應避免產生或加強不公平的偏見)。我們力求避免對人們造成不公正的影響，特別是那些與種族、民族、性別、國籍、收入、性取向、能力以及政治或宗教信仰等敏感特徵相關的影響。
3. AI should be built and tested for safety (AI 的建構和測試應以安全為前提)。我們將繼續開發和應用強大的安全措施，以避免產生造成傷害風險的意外結果。
4. AI should be accountable to people (AI 應對人負責)。我們將設計提供適當的回饋、相關解釋和申訴機會的 AI 系統。
5. AI should incorporate privacy design principles (AI 應納入隱私設計原則)。我們將提供通知和同意的機會，鼓勵使用具有隱私保護的架構，並提供對數據使用的適當透明度和控制。
6. AI should uphold high standards of scientific excellence (AI 應秉持高標準的科學卓越性)。我們將與各方合作，促進該領域周到的領導，採用科學嚴謹和多學科的方法，並透過發布教育材料、最佳實踐和研究來負責任地分享 AI 知識，使更多人能夠開發有用的 AI 應用程式。
7. AI should be made available for uses that accord with these principles (AI 的應用應符合這些原則)。許多技術都有多種用途，因此我們將努力限制潛在有害或濫用的應用。

**五、AI Applications Google Will Not Pursue**

除了這七項原則外，Google 還有某些不會追求的 AI 應用領域。他們不會在以下四個應用領域設計或部署 AI：

- 導致或可能導致整體損害的技術。
- 主要目的是造成或直接促成人身傷害的武器或其他技術。
- 收集或使用資訊進行監控，違反國際公認規範的技術。
- 目的違反廣泛接受的國際法和人權原則的技術。

**六、Conclusion**

建立原則是一個起點，而不是終點。重要的是，Google 的 AI 原則很少能直接回答關於如何建構產品的問題。它們不應該也不允許我們迴避艱難的對話。它們是一個基礎，確立了我們的立場、我們建構的內容以及我們建構的原因，而其核心是我們的企業 AI 產品的成功。