# 7.2.3 How do we review conversations?

**如何審查對話**

在 Feedback Loop (回饋循環) 的 Understand (理解) 階段，審查對話記錄是關鍵步驟。本節探討如何進行對話審查。

**審查對話記錄的兩種主要方式：**

1. **Manual review (手動審查)：**
    - **方式：** 由真人客服 (human agents) 聆聽或閱讀記錄下來的對話，並做筆記。
    - **優點：** 可以提供自動化方法可能遺漏的有價值的 **qualitative insights (定性洞察)**。
    - **缺點：** 可能是一個**耗時 (time-consuming)** 的過程。
2. **Targeted review (目標審查)：**
    - **方式：** 使用更多 **filters (篩選器)** 來審查一組彼此更相關的對話 (例如，具有共同的 user utterance - 使用者語句 或 detected intent - 偵測到的意圖)。

- **選擇：** 最佳方法取決於 conversational agent 的規模與複雜度，以及可用資源。但無論選擇哪種方法，將對話記錄審查作為 **feedback loop 的常規部分**都很重要，以便持續改善 agent performance (代理程式效能)。

**審查前的準備：設定目標與建立模板**

1. **設定明確目標 (Set a specific goal)：**
    - **重要性：** 在深入研究 transcripts (逐字稿) 之前，設定目標有助於保持專注，確保收集到改進 conversational agent 所需的反饋，並使結果符合團隊需求。(避免收集無法解決特定弱點的通用反饋)。
    - **常見目標範例：**
        - **意圖收集的有效性 (Effectiveness of intent gathering)：** 使用者的 utterances 是否被標記到正確的 intent？
        - **機器人對實體的理解 (Bot's understanding of entities)：** Agent 能否正確識別和解釋使用者請求的關鍵元素 (如 names, dates, locations)？
        - **代理程式回應的適當性 (Appropriateness of agent responses)：** Agent 回應使用者的方式是否自然、有幫助，且與您的 brand voice (品牌聲音) 一致？
    - **聚焦審查：** 設定目標後，可針對性地調整審查流程 (例如，若目標是改善意圖收集，則特別關注使用者難以表達請求或 agent 誤解意圖的情況)。
2. **建立資訊收集模板 (Create a template)：**
    - **目的：** 建立模板 (例如使用 **Google Sheet**) 來收集 transcripts 中的資訊 (包含 user's query, agent's response, conversation successful? 等欄位)。
    - **效益：** 設定評分指南和一致的格式，有助於整合來自不同審閱者的結果，因為不同審閱者可能評價不同。確保提供清晰定義以保證收集過程的一致性。

**執行審查的步驟：**

1. **抽取隨機樣本 (Pull a random sample)：** 審查**隨機樣本**以**避免偏見 (avoid bias)**。若只審查被報告有問題的對話，會對 agent performance 產生**偏頗的看法 (skewed view)**。可透過在 conversation history 中設定 filters 並按 ID (隨機生成) 排序來實現。
2. **持續審查 (Continue to review)：** 投入時間建立清晰目標和穩健模板，能確保更有用的產出。定期與審閱者 **check-in**，了解是否有模板設定時未預料到的問題發生。
3. **關注要點 (Pay attention to)：**
    - Agent 理解使用者 query 的程度 (是否正確識別 intent？)。
    - Agent responses 的品質 (是否清晰、簡潔、有幫助？)。
    - Agent 完成任務的能力 (是否能幫助使用者達成目標？)。
4. **記錄與匯總觀察 (Document high-level observations)：**
    - 在審查時記錄觀察到的高層次現象。
    - 匯總所有審閱者的回應，對行為進行共同的 **disposition (定性/分類)**。
    - 這些觀察可用於識別 **trends (趨勢)** 和 **patterns (模式)**，幫助改進 agent。
    - 將行為**編目 (Catalog)**，以供團隊進行 **prioritization (優先級排序)** 和討論。
5. **分享結果 (Share results)：** 審查完樣本後，匯總結果並與團隊分享，幫助團隊成員了解 agent 表現並識別改進領域。

**此步驟的限制與權衡 (Limitations)：**

- **Manual Review (手動審查)：**
    - **優點：** 能對個別對話進行最深入的分析，識別具體優缺點，理解 user intent，診斷問題的 root cause (根本原因)。
    - **缺點：** 耗時且**不可擴展 (not scalable)**，對話量大時難以全部審閱。
- **Automated Trend Detection (自動化趨勢偵測)：**
    - **優點：** 可分析大量對話數據，識別手動審查難以發現的 patterns 和 trends，幫助排定工作優先級，聚焦最緊迫的問題。
    - **缺點：** 可能無法提供與手動審查相同層級的細節，且可能遺漏某些重要問題。
- **建議方法：** 最佳方法通常是**混合使用 (blend)**，取決於具體需求和資源。對話量少時可選手動；對話量大或需快速識別趨勢時，自動化可能是更好選擇。

**總結來說，** 審查對話記錄是 FBL 理解階段的關鍵執行步驟。可以採用深入但耗時的「手動審查」，或利用篩選器分析特定對話子集的「目標審查」。無論哪種方式，都應先設定清晰的審查「目標」，並建立「模板」以確保評估標準和數據收集的一致性。審查時需抽取「隨機樣本」避免偏見，關注 Agent 理解、回應品質、任務完成度等方面，記錄觀察並匯總結果供團隊討論。雖然手動審查洞察最深，但面對大量數據時需考慮結合「自動化趨勢偵測」來提升效率與擴展性，採取混合方法通常是最佳策略。