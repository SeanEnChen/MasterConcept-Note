# 8.2.5 A/B Testing (Experiments)

**A/B Testing / Experiments**

本節探討最後一種測試類型：**A/B testing (A/B 測試)**，在 **Dialogflow CX** 中通常稱為 **Experiments (實驗)**。

**A/B Testing / Experiments 的定義與目的：**

- **定義：** 一種 **UX methodology (使用者體驗方法論)**，涉及進行 **randomized experiment (隨機實驗)** 來比較兩個或多個 systems (系統) 或 conversational experiences (對話體驗) 的 **performance (效能)**。
- **目的：** 驗證哪個 **versions (版本)** 能更好地滿足 **project scope (專案範疇)** 或 **specifications (規格)** 中概述的 **functional requirements (功能需求)**。

**在 Dialogflow CX 中實施 Experiments：**

- **工具：** 可透過 Dialogflow CX **內建的 experiments feature (實驗功能)** 來完成。
- **環境：** 應盡可能在與 production environment (生產環境) 相似的環境中進行開發和測試，通常稱為 **pre-prod (預生產)** 環境。
- **運作方式：** Experiments 允許開發團隊將一部分 **live traffic (真實流量)** 分配給不同的 **flow versions (流程版本)**。

**用於比較實驗版本的常見 Metrics (衡量指標)：**

監控實驗效能時常用的 metrics 包括：

- **Live agent handoff rate (真人客服轉接率)：** 轉接給真人客服的 sessions 數量。
- **Session end-rate (對話階段結束率)：** 到達 `END_SESSION` 狀態的 sessions 數量。
- **Total no-match count (總無法匹配次數)：** 發生 no-match event (事件) 的總次數。
- **Total turn count (總對話輪次)：** (一個 end-user input 和一個 agent response 算一輪)。
- **Average turn count (平均對話輪次)。**
- **Contained (自助完成的對話階段數)：** 到達 `END_SESSION` 且未觸發下方其他 (通常為負面) 指標的 sessions 數量。
- **Callback rate (回撥率)：** 被 end-user 重新啟動的 sessions 數量。
- **Abandoned rate (放棄率)：** 被 end-user 放棄的 sessions 數量。
- **結果解讀：** 在 Dialogflow CX console 中，**Green (綠色)** 結果通常表示**有利 (favorable)**，**Red (紅色)** 表示**較不利 (less favorable)**。但需注意，有時數字高低本身不一定代表好壞 (例如，低放棄率通常是好的，但需結合其他指標看)。

**實驗的執行流程：**

1. **逐步放量 (Gradual Rollout)：** 當有新的 agent 或 flow 版本要測試時，先將其暴露給**小百分比**的使用者流量。
2. **評估與增加流量：** 如果初步結果是正面的，可以**逐漸增加 (gradually increase)** 流量，以提供更具**統計顯著性 (statistically significant)** 的評估集。
3. **決策：** 根據評估結果決定是**繼續推進 (move forward)** 新版本，還是 **revert (恢復)** 到現有版本。
4. **並行實驗：** Dialogflow 的 Experiments 功能允許**同時運行多個實驗**，以加快測試過程。

**Experiments / A/B Testing 的效益：**

- **測試新想法：** 讓設計師能夠測試可能挑戰傳統智慧的新想法 (關於 virtual agents 應如何處理特定情況或流程)。
- **數據驅動決策：** 可獲取**量化指標 (quantitative metrics)** 來為決策提供資訊，而非僅依賴直覺。
- **準確比較：** 當流量比例增加到 **50/50 split** 時，可以在受控設定下收集指標，對兩個版本的相對效能進行準確評估。
- **促進文化：** 培養**數據驅動的文化 (data-driven culture)**。
- **加速發布：** 有助於**加速發布流程 (expedite the release process)**。
- **最佳體驗：** 確保為使用者提供**最佳的對話體驗 (best conversational experience)**。

**總結來說，** A/B Testing (在 Dialogflow CX 中稱為 Experiments) 是在將變更全面推向生產環境前的最後一個關鍵測試階段。它利用隨機實驗將部分真實流量導向不同版本的流程，並透過比較如轉接率、結束率、No-match 次數、對話輪次、自助完成率、回撥率、放棄率等關鍵指標，以數據驅動的方式評估哪個版本表現更好。執行時應採逐步放量策略，從少量流量開始，若結果正面再逐漸增加至 50/50 以進行精確比較，最終決定採用哪個版本。這個功能有助於驗證新想法、加速發布並確保提供最佳的使用者體驗。