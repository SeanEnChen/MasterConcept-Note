# 4.1 Gen AI and human-like conversation design

**Conversation Design (CxD) 基礎課程介紹**

- 本課程旨在引導學習者掌握打造引人入勝且有效的、模擬真人體驗的 **chat experiences (聊天體驗)** 的基本要素。(注意：雖然後續原則也適用於 Voice，但本節重點在 Chat)。
- **課程內容概覽：**
    - **Conversation Design (CxD)** 的全面介紹。
    - 將聊天設計與 **business objectives (業務目標)** 對齊的策略。
    - 如何建立 **user personas (使用者輪廓)**。
    - 如何撰寫引人入勝的 **chat scripts (聊天腳本)**。
    - 如何增強每個 **conversational turn (對話輪次)**。
    - 撰寫 **guardrails (護欄)** 以確保對話不偏離軌道的最佳方法。
    - 如何優雅地處理 **chatbot** 無法滿足使用者請求的 **fallback (後備)** 情況。

**Gen AI 在類人對話設計中的角色：**

- **LLMs (大型語言模型) 的特性：** 通常是基於大量文本訓練的 **generalists (通才)**，允許使用者以 **divergent way (發散方式)** 就廣泛主題進行提問或聊天。
- **純 LLM 的挑戰：** 對於目標明確的任務 (例如，報告財產損壞)，LLM 的開放性和看似無限的可能性，反而可能因提供過多無關上下文或選項而導致使用者脫離，帶來挫敗感。
- **純 Deterministic (決定性) 設計的挑戰：** 基於 **intent (意圖)** 的傳統設計能完成任務，但使用者可能感覺在與 **無個性的 robot (機器人)** 對話，而非有幫助的助理。且當遇到無法處理的意外情況 (如使用者不知如何上傳照片) 時，容易產生 **no-match (無法匹配)**。

**Divergent (發散) vs. Convergent (收斂) 思維：**

- **Convergent thinking (收斂思維)：** 專注於為問題找到一個明確定義的解決方案，適用於涉及**邏輯**而非創意的任務 (例如，解決只有唯一解的問題)。
- **Divergent thinking (發散思維)：** 與收斂思維相反，涉及更多**創意**，探索多種可能性。優點是能發現新機會、找到創意解法；缺點是可能偏離達成共同目標的路徑。
- **應用於對話設計：**
    - 設計與使用者的對話時，當涉及**選項和可能性**時，我們希望是 **divergent (發散)** 的。
    - 當試圖幫助使用者**解決問題或進行交易**時，我們希望是 **convergent (收斂)** 的。
- **應用於 LLMs 與 Virtual Agents：**
    - **Divergent thinking (LLMs 更擅長)：** 適合創意性、開放式對話 (如幫助使用者學習、回答 FAQs)。
    - **Convergent thinking (傳統 Virtual Agents 更擅長)：** 適合專注的、目標導向的對話 (幫助使用者解決特定問題)。

**核心設計原則："Leverage Gen AI for the Long Tail" (利用 Gen AI 處理長尾)**

- **概念 (孔雀比喻)：**
    - **頭部 (Head - Deterministic Focus)：** 佔對話路徑約 20%，但涵蓋 80% 的使用者。這是**最重要、最常見**的對話路徑，也是 **critical use-cases (關鍵使用案例)** (例如，報失護照、掛失信用卡等 **transactional use-cases - 交易型使用案例**)。應將**大部分設計精力**投入於此，確保提供絕佳的使用者體驗。這些路徑通常圍繞清晰的 intents，需要 **deterministic prompts (決定性提示)** 來收集和驗證觸發後端動作所需的 structured data (結構化數據)。**不建議**將這些關鍵互動完全「委派」給開放式的 LLM。
    - **身體與尾巴 (Body & Tail - Gen AI Handling)：** 代表 **common detours (常見的繞路)** (較不常見、直接或成功的路徑) 和 **long tail of edge cases (長尾的邊緣案例)** (極不常見的路徑)。**不能忽略**這些路徑，需讓 **LLMs** 來處理這些佔比約 80% 的路徑 (涵蓋剩餘 20% 的使用者)。
- **範例應用：** **Generative Fallback** 功能就是一個例子，它使用 Google 最新的 generative LLMs，在使用者輸入**未匹配任何 intent 或 parameter (參數)** 時生成 virtual agent 回應，以處理 **conversation fallout (對話失敗/異常)**。只需透過 **text prompt** 指示 LLM 如何回應即可。

**使用 LLMs 的重要考量：**

雖然 LLMs 在處理發散性思維的 use cases 時表現出色，但在設計時需謹記：

1. **法規限制 (Regulation)：** 關鍵行業 (如 **finance - 金融**, **healthcare - 醫療**, **retail - 零售**) 在 **data-privacy (資料隱私)** 和 **fairness (公平性)** 方面受到嚴格監管，限制了對話設計的彈性。
2. **安全威脅 (Security Threats)：** 基於 LLM 且處理非常敏感使用者輸入的應用，可能面臨 **prompt injection (提示注入)** 的風險。
3. **非確定性回應的審查 (Scrutiny for Non-deterministic Responses)：** VA 中配置的任何 **non-deterministic response (非確定性回應)** 都需要仔細審查，因此需要嚴格的 **quality assurance (QA) protocols (品質保證協議)** 來進行測試。

**總結來說，** Conversation Design (CxD) 的基礎在於理解如何平衡傳統的 Deterministic 設計與新興的 Gen AI/LLM 能力。應採用 "Leverage Gen AI for the Long Tail" 的原則：將主要設計精力投入到核心、常見的對話路徑 (孔雀頭部)，確保其穩定可靠且符合業務邏輯；同時利用 LLMs 的發散能力和 Generative Fallback 等功能來處理大量的、非核心的、預料之外的對話分支或無匹配情況 (孔雀身體與尾巴)，從而創造既高效又能處理長尾問題、更接近真人體驗的對話。然而，在應用 LLM 時，必須充分考慮行業法規、潛在的安全風險以及對非確定性回應的嚴格測試。